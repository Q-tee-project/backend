from celery import current_task
from sqlalchemy.orm import Session
import json
from datetime import datetime
from typing import Dict, Any, List
from concurrent.futures import ThreadPoolExecutor, as_completed

from .celery_app import celery_app
from .database import SessionLocal
from .core.config import get_settings
from .schemas.generation import WorksheetGenerationRequest
from .schemas.regeneration import RegenerateEnglishQuestionRequest
from .schemas.validation import QuestionValidationResult
from .services.generation.question_generator import PromptGenerator
from .services.regeneration.question_regenerator import QuestionRegenerator
from .services.validation.validator import QuestionValidator
from .services.validation.judge import QuestionJudge
from .core.validation_config import VALIDATION_SETTINGS

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

settings = get_settings()


def get_session():
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±"""
    return SessionLocal()


def call_gemini_for_question(prompt_info: Dict[str, Any]) -> Dict[str, Any]:
    """ë¬¸ì œ ìƒì„±ì„ ìœ„í•œ Gemini API í˜¸ì¶œ (ë…í•´ëŠ” ì§€ë¬¸ í¬í•¨)"""
    try:
        question_id = prompt_info['question_id']
        needs_passage = prompt_info.get('needs_passage', False)
        prompt = prompt_info['prompt']

        if needs_passage:
            print(f"ğŸ“šâ“ ë…í•´ ë¬¸ì œ {question_id} (ì§€ë¬¸ í¬í•¨) ìƒì„± ì‹œì‘...")
        else:
            print(f"â“ ë¬¸ì œ {question_id} ìƒì„± ì‹œì‘...")

        # Gemini API í‚¤ ì„¤ì •
        genai.configure(api_key=settings.gemini_api_key)

        # Gemini ëª¨ë¸ ìƒì„± (2.5 Flash ì‚¬ìš©)
        model = genai.GenerativeModel(settings.gemini_flash_model)

        # API í˜¸ì¶œ
        response = model.generate_content(
            prompt,
            generation_config={"response_mime_type": "application/json"}
        )

        # JSON íŒŒì‹±
        result = json.loads(response.text)

        if needs_passage:
            print(f"âœ… ë…í•´ ë¬¸ì œ {question_id} (ì§€ë¬¸ í¬í•¨) ìƒì„± ì™„ë£Œ!")
        else:
            print(f"âœ… ë¬¸ì œ {question_id} ìƒì„± ì™„ë£Œ!")

        return result

    except Exception as e:
        print(f"âŒ ë¬¸ì œ {prompt_info['question_id']} ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise Exception(f"ë¬¸ì œ {prompt_info['question_id']} ìƒì„± ì‹¤íŒ¨: {str(e)}")


def call_gemini_for_validation(prompt: str) -> QuestionValidationResult:
    """ë¬¸ì œ ê²€ì¦ì„ ìœ„í•œ Gemini API í˜¸ì¶œ (AI Judge)"""
    try:
        print(f"ğŸ” AI Judge ê²€ì¦ ì‹œì‘...")

        # Gemini API í‚¤ ì„¤ì •
        genai.configure(api_key=settings.gemini_api_key)

        # Gemini ëª¨ë¸ ìƒì„± (Pro ëª¨ë¸ ì‚¬ìš© - ê²€ì¦ì€ ë” ì •í™•í•œ ëª¨ë¸ ì‚¬ìš©)
        model = genai.GenerativeModel(settings.gemini_model)

        # API í˜¸ì¶œ (response_schema ì—†ì´ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©)
        response = model.generate_content(
            prompt,
            generation_config={
                "response_mime_type": "application/json"
            }
        )

        # JSON íŒŒì‹± ë° Pydantic ë³€í™˜
        result_dict = json.loads(response.text)
        validation_result = QuestionValidationResult.model_validate(result_dict)

        print(f"âœ… AI Judge ê²€ì¦ ì™„ë£Œ: {validation_result.final_judgment} ({validation_result.total_score}/100)")

        return validation_result

    except Exception as e:
        print(f"âŒ AI Judge ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        raise Exception(f"AI Judge ê²€ì¦ ì‹¤íŒ¨: {str(e)}")


def generate_questions_parallel(question_prompts: List[Dict[str, Any]], enable_validation: bool = False) -> Dict[str, Any]:
    """
    ë¬¸ì œë“¤ì„ ë³‘ë ¬ë¡œ ìƒì„± (ë…í•´ëŠ” ì§€ë¬¸ í¬í•¨)

    Args:
        question_prompts: ë¬¸ì œ í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸
        enable_validation: AI Judge ê²€ì¦ í™œì„±í™” ì—¬ë¶€
    """

    print(f"ğŸš€ ë¬¸ì œ ë³‘ë ¬ ìƒì„± ì‹œì‘ ({len(question_prompts)}ê°œ)...")
    if enable_validation:
        print(f"âœ… AI Judge ê²€ì¦ í™œì„±í™”ë¨ (ìµœëŒ€ {VALIDATION_SETTINGS['max_retries']}íšŒ ì¬ì‹œë„)")

    results = []
    validation_results = []

    def generate_with_validation(prompt_info: Dict[str, Any]) -> tuple:
        """ë‹¨ì¼ ë¬¸ì œ ìƒì„± + ê²€ì¦"""
        question_id = prompt_info['question_id']
        metadata = prompt_info.get('metadata', {})

        if not enable_validation:
            # ê²€ì¦ ì—†ì´ ë°”ë¡œ ìƒì„±
            question_data = call_gemini_for_question(prompt_info)
            return question_data, None

        # ê²€ì¦ í¬í•¨ ìƒì„±
        validator = QuestionValidator(
            max_retries=VALIDATION_SETTINGS['max_retries']
        )
        judge = QuestionJudge()

        best_question = None
        best_validation = None
        best_score = -1

        for attempt in range(1, VALIDATION_SETTINGS['max_retries'] + 1):
            try:
                # ë¬¸ì œ ìƒì„±
                question_data = call_gemini_for_question(prompt_info)

                # ê²€ì¦ í”„ë¡¬í”„íŠ¸ ìƒì„±
                judge_prompt = judge.create_judge_prompt(question_data, metadata)

                # AI Judge ê²€ì¦
                validation_result = call_gemini_for_validation(judge_prompt)

                # ìµœê³  ì ìˆ˜ ì¶”ì 
                if validation_result.total_score > best_score:
                    best_score = validation_result.total_score
                    best_question = question_data
                    best_validation = validation_result

                # Pass íŒì •ì´ë©´ ë°”ë¡œ ì‚¬ìš©
                if validation_result.final_judgment == "Pass":
                    print(f"âœ… ë¬¸ì œ {question_id}: Pass íŒì • (attempt {attempt}, score {validation_result.total_score}/100)")
                    return question_data, validation_result

                # ì¬ì‹œë„ í•„ìš”
                print(f"âš ï¸ ë¬¸ì œ {question_id}: {validation_result.final_judgment} (attempt {attempt}, score {validation_result.total_score}/100)")

            except Exception as e:
                print(f"âŒ ë¬¸ì œ {question_id} ê²€ì¦ ì¤‘ ì˜¤ë¥˜ (attempt {attempt}): {str(e)}")
                if attempt >= VALIDATION_SETTINGS['max_retries']:
                    # ìµœëŒ€ ì‹œë„ ë„ë‹¬ - ìµœê³  ì ìˆ˜ ë¬¸ì œ ì‚¬ìš©
                    if best_question:
                        print(f"âš ï¸ ë¬¸ì œ {question_id}: ìµœê³  ì ìˆ˜ ë²„ì „ ì‚¬ìš© (score {best_score}/100)")
                        return best_question, best_validation
                    raise

        # ìµœëŒ€ ì‹œë„ í›„ ìµœê³  ì ìˆ˜ ë¬¸ì œ ì‚¬ìš©
        print(f"âš ï¸ ë¬¸ì œ {question_id}: ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬. ìµœê³  ì ìˆ˜ ë²„ì „ ì‚¬ìš© (score {best_score}/100)")
        return best_question, best_validation

    # ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=len(question_prompts)) as executor:
        future_to_prompt = {
            executor.submit(generate_with_validation, prompt): prompt
            for prompt in question_prompts
        }

        # ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ìˆ˜ì§‘
        for future in as_completed(future_to_prompt):
            try:
                question_data, validation_result = future.result()
                results.append(question_data)
                if validation_result:
                    validation_results.append(validation_result)
            except Exception as e:
                prompt_info = future_to_prompt[future]
                print(f"âŒ ë¬¸ì œ {prompt_info['question_id']} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                raise

    # question_id ìˆœì„œë¡œ ì •ë ¬
    results.sort(key=lambda x: x.get('question', x).get('question_id'))

    # ë…í•´ ë¬¸ì œ(passage í¬í•¨)ì™€ ì¼ë°˜ ë¬¸ì œ ë¶„ë¦¬
    passages = []
    questions = []

    for result in results:
        if 'passage' in result:
            # ë…í•´ ë¬¸ì œ: passageì™€ question ë¶„ë¦¬
            passages.append(result['passage'])
            questions.append(result['question'])
        else:
            # ë¬¸ë²•/ì–´íœ˜ ë¬¸ì œ: questionë§Œ
            questions.append(result)

    # ê²€ì¦ ê²°ê³¼ ìš”ì•½
    if enable_validation and validation_results:
        pass_count = sum(1 for v in validation_results if v.final_judgment == "Pass")
        avg_score = sum(v.total_score for v in validation_results) / len(validation_results)
        print(f"ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½: Pass {pass_count}/{len(validation_results)}, í‰ê·  ì ìˆ˜ {avg_score:.1f}/100")

    print(f"âœ… ëª¨ë“  ë¬¸ì œ ìƒì„± ì™„ë£Œ! (ì§€ë¬¸ {len(passages)}ê°œ, ë¬¸ì œ {len(questions)}ê°œ)")
    return {
        'passages': passages,
        'questions': questions,
        'validation_results': validation_results if enable_validation else None
    }


def assemble_worksheet(passages: List[Dict[str, Any]], questions: List[Dict[str, Any]], request_data: Dict[str, Any]) -> str:
    """ì›Œí¬ì‹œíŠ¸ ìµœì¢… ì¡°ë¦½"""

    print(f"ğŸ”§ ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½ ì‹œì‘...")

    school_level = request_data.get('school_level', 'ì¤‘í•™êµ')
    grade = request_data.get('grade', 1)
    total_questions = len(questions)

    # ì˜ì—­ ë¶„í¬ ê³„ì‚°
    subjects = set(q['question_subject'] for q in questions)
    if len(subjects) == 1:
        problem_type = list(subjects)[0]
    else:
        problem_type = 'í˜¼í•©í˜•'

    # related_questions ì—…ë°ì´íŠ¸
    for passage in passages:
        passage['related_questions'] = [
            q['question_id'] for q in questions
            if q.get('question_passage_id') == passage['passage_id']
        ]

    worksheet = {
        "worksheet_id": 1,
        "worksheet_name": "",
        "worksheet_date": datetime.now().strftime("%Y-%m-%d"),
        "worksheet_time": datetime.now().strftime("%H:%M"),
        "worksheet_duration": "60",
        "worksheet_subject": "english",
        "worksheet_level": school_level,
        "worksheet_grade": grade,
        "problem_type": problem_type,
        "total_questions": total_questions,
        "passages": passages,
        "questions": questions
    }

    print(f"âœ… ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½ ì™„ë£Œ! (ì´ {total_questions}ë¬¸ì œ, {len(passages)}ì§€ë¬¸)")

    return json.dumps(worksheet, ensure_ascii=False)


@celery_app.task(bind=True, name="app.tasks.generate_english_worksheet_task")
def generate_english_worksheet_task(self, request_data: dict):
    """ì˜ì–´ ì›Œí¬ì‹œíŠ¸ ìƒì„± ë¹„ë™ê¸° íƒœìŠ¤í¬"""

    task_id = self.request.id
    print(f"ğŸš€ English worksheet generation task started: {task_id}")

    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        request = WorksheetGenerationRequest.model_validate(request_data)

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì‹œì‘ (10%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'ë¬¸ì œ ìƒì„± ì˜µì…˜ ì²˜ë¦¬ ì¤‘...'}
        )

        print("ğŸ¯ ë¬¸ì œ ìƒì„± ì˜µì…˜ ì²˜ë¦¬:")
        print(f" í•™êµê¸‰: {request.school_level}")
        print(f" í•™ë…„: {request.grade}í•™ë…„")
        print(f" ì´ ë¬¸ì œ ìˆ˜: {request.total_questions}ê°œ")
        print(f" ì„ íƒëœ ì˜ì—­: {', '.join(request.subjects)}")

        # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
        db = get_session()

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - í”„ë¡¬í”„íŠ¸ ìƒì„± (30%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 30, 'total': 100, 'status': 'í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...'}
        )

        # í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        print("ğŸ¯ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘...")
        generator = PromptGenerator()

        # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        request_dict = request.model_dump()

        # ë¶„ë°° ìš”ì•½ ìƒì„±
        distribution_summary = generator.get_distribution_summary(request_dict)

        print("ğŸ“Š ë¶„ë°° ê²°ê³¼:")
        print(f"  ì´ ë¬¸ì œ ìˆ˜: {distribution_summary['total_questions']}")
        print("  ì˜ì—­ë³„ ë¶„ë°°:")
        for item in distribution_summary['subject_distribution']:
            print(f"    {item['subject']}: {item['count']}ë¬¸ì œ ({item['ratio']}%)")

        # === 1ë‹¨ê³„: ë¬¸ì œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ë…í•´ëŠ” ì§€ë¬¸ ìƒì„± í¬í•¨) ===
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 30, 'total': 100, 'status': 'ë¬¸ì œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...'}
        )

        try:
            print("ğŸ” 1ë‹¨ê³„: ë¬¸ì œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œë„ ì¤‘ (ë…í•´ëŠ” ì§€ë¬¸ í¬í•¨)...")
            question_prompts = generator.generate_question_prompts(request_dict, passages=None, db=db)
            print(f"âœ… ë¬¸ì œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ! ({len(question_prompts)}ê°œ)")
        except Exception as prompt_error:
            print(f"âŒ ë¬¸ì œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {prompt_error}")
            db.close()
            raise Exception(f"ë¬¸ì œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(prompt_error)}")

        # === 2ë‹¨ê³„: ë¬¸ì œ ë³‘ë ¬ ìƒì„± (ë…í•´ëŠ” ì§€ë¬¸ í¬í•¨) ===
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 60, 'total': 100, 'status': 'ë¬¸ì œ ë° ì§€ë¬¸ ë³‘ë ¬ ìƒì„± ì¤‘...'}
        )

        passages = []
        questions = []
        llm_error = None

        if GEMINI_AVAILABLE:
            try:
                # Gemini API í‚¤ í™•ì¸
                if not settings.gemini_api_key:
                    raise Exception("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                # AI Judge ê²€ì¦ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: ì„¤ì • íŒŒì¼ ì°¸ì¡°)
                enable_validation = request_data.get('enable_validation', VALIDATION_SETTINGS['enable_by_default'])

                # ë¬¸ì œ ë³‘ë ¬ ìƒì„± (ë…í•´ëŠ” ì§€ë¬¸ í¬í•¨, ê²€ì¦ ì˜µì…˜)
                result = generate_questions_parallel(question_prompts, enable_validation=enable_validation)
                passages = result['passages']
                questions = result['questions']

            except Exception as api_error:
                print(f"âŒ ë¬¸ì œ ìƒì„± ì˜¤ë¥˜: {api_error}")
                llm_error = str(api_error)
                db.close()
                raise Exception(f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(api_error)}")
        else:
            llm_error = "Gemini ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            db.close()
            raise Exception(llm_error)

        # === 3ë‹¨ê³„: ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½ ===
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 90, 'total': 100, 'status': 'ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½ ì¤‘...'}
        )

        llm_response = None
        parsed_llm_response = None

        try:
            # ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½
            llm_response = assemble_worksheet(passages, questions, request_dict)

            # JSON íŒŒì‹±
            parsed_llm_response = json.loads(llm_response)
            print("âœ… ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½ ë° íŒŒì‹± ì™„ë£Œ!")

        except Exception as e:
            print(f"âŒ ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½ ì˜¤ë¥˜: {e}")
            db.close()
            raise Exception(f"ì›Œí¬ì‹œíŠ¸ ì¡°ë¦½ ì‹¤íŒ¨: {str(e)}")

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì™„ë£Œ (100%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 100, 'total': 100, 'status': 'ì™„ë£Œ!'}
        )

        # ë°±ì—”ë“œì—ì„œ ê²°ê³¼ ì¶œë ¥
        print("=" * 80)
        print("ğŸ‰ ë¬¸ì œì§€ ë° ë‹µì•ˆì§€ ìƒì„± ì™„ë£Œ!")
        print("=" * 80)
        if parsed_llm_response:
            print(f"ğŸ“„ ë¬¸ì œì§€ ID: {parsed_llm_response.get('worksheet_id', 'N/A')}")
            print(f"ğŸ“ ë¬¸ì œì§€ ì œëª©: {parsed_llm_response.get('worksheet_name', 'N/A')}")
            print(f"ğŸ“Š ì´ ë¬¸ì œ ìˆ˜: {parsed_llm_response.get('total_questions', 'N/A')}ê°œ")
            print(f"ğŸ” ë¬¸ì œ ìœ í˜•: {parsed_llm_response.get('problem_type', 'N/A')}")
        print("=" * 80)

        db.close()

        # ê¸°ì¡´ê³¼ ë™ì¼í•œ í˜•íƒœë¡œ ë°˜í™˜ (DB ì €ì¥í•˜ì§€ ì•ŠìŒ)
        return {
            "message": "ë¬¸ì œì§€ì™€ ë‹µì•ˆì§€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            "status": "success",
            "llm_response": parsed_llm_response,  # ìƒì„±ëœ JSONì„ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬
            "llm_error": llm_error,
        }

    except Exception as e:
        print(f"âŒ ì˜ì–´ ì›Œí¬ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

        # íƒœìŠ¤í¬ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        current_task.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ë¬¸ì œ ìƒì„± ì‹¤íŒ¨'}
        )

        raise Exception(f"ì˜ì–´ ì›Œí¬ì‹œíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")


@celery_app.task(bind=True, name="app.tasks.get_task_status")
def get_task_status(self, task_id: str):
    """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
    try:
        result = celery_app.AsyncResult(task_id)

        if result.state == 'PENDING':
            response = {
                'state': result.state,
                'status': 'ëŒ€ê¸° ì¤‘...'
            }
        elif result.state == 'PROGRESS':
            response = {
                'state': result.state,
                'current': result.info.get('current', 0),
                'total': result.info.get('total', 100),
                'status': result.info.get('status', '')
            }
        elif result.state == 'SUCCESS':
            response = {
                'state': result.state,
                'result': result.info
            }
        else:  # FAILURE
            response = {
                'state': result.state,
                'error': str(result.info)
            }

        return response

    except Exception as e:
        return {
            'state': 'FAILURE',
            'error': f'íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }


@celery_app.task(bind=True, name="app.tasks.regenerate_english_question_task")
def regenerate_english_question_task(self, request_data: dict):
    """ì˜ì–´ ë¬¸ì œ ì¬ìƒì„± ë¹„ë™ê¸° íƒœìŠ¤í¬"""

    task_id = self.request.id
    print(f"ğŸ”„ English question regeneration task started: {task_id}")

    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        request = RegenerateEnglishQuestionRequest.model_validate(request_data)

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì‹œì‘ (10%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'ì¬ìƒì„± ì˜µì…˜ ì²˜ë¦¬ ì¤‘...'}
        )

        print("ğŸ”„ ë¬¸ì œ ì¬ìƒì„± ì˜µì…˜ ì²˜ë¦¬:")
        print(f" ëŒ€ìƒ ë¬¸ì œ ìˆ˜: {len(request.questions)}ê°œ")
        print(f" ì§€ë¬¸ ì¬ìƒì„±: {'ìˆìŒ' if request.passage else 'ì—†ìŒ'}")
        print(f" ì‚¬ìš©ì í”¼ë“œë°±: {request.formData.feedback}")

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì¬ìƒì„± ì‹œì‘ (30%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 30, 'total': 100, 'status': 'ë¬¸ì œ ì¬ìƒì„± ì¤‘...'}
        )

        # ë¬¸ì œ ì¬ìƒì„±ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        print("ğŸ¯ ë¬¸ì œ ì¬ìƒì„± ì‹œì‘...")
        regenerator = QuestionRegenerator()

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - AI ì²˜ë¦¬ (60%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 60, 'total': 100, 'status': 'AI ì¬ìƒì„± ì²˜ë¦¬ ì¤‘...'}
        )

        # ì¬ìƒì„± ì‹¤í–‰
        success, message, regenerated_questions, regenerated_passage = regenerator.regenerate_from_data(
            questions=request.questions,
            passage=request.passage,
            form_data=request.formData
        )

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ê²°ê³¼ ì²˜ë¦¬ (80%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 80, 'total': 100, 'status': 'ì¬ìƒì„± ê²°ê³¼ ì²˜ë¦¬ ì¤‘...'}
        )

        if success:
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì™„ë£Œ (100%)
            current_task.update_state(
                state='PROGRESS',
                meta={'current': 100, 'total': 100, 'status': 'ì¬ìƒì„± ì™„ë£Œ!'}
            )

            # ë°±ì—”ë“œì—ì„œ ê²°ê³¼ ì¶œë ¥
            print("=" * 80)
            print("ğŸ‰ ë¬¸ì œ ì¬ìƒì„± ì™„ë£Œ!")
            print("=" * 80)
            print(f"ğŸ“ ì¬ìƒì„±ëœ ë¬¸ì œ ìˆ˜: {len(regenerated_questions) if regenerated_questions else 0}ê°œ")
            print(f"ğŸ“„ ì¬ìƒì„±ëœ ì§€ë¬¸: {'ìˆìŒ' if regenerated_passage else 'ì—†ìŒ'}")
            print("=" * 80)

            # Pydantic ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            serialized_questions = None
            if regenerated_questions:
                serialized_questions = [q.model_dump() if hasattr(q, 'model_dump') else q for q in regenerated_questions]

            serialized_passage = None
            if regenerated_passage:
                serialized_passage = regenerated_passage.model_dump() if hasattr(regenerated_passage, 'model_dump') else regenerated_passage

            return {
                "status": "success",
                "message": message,
                "regenerated_questions": serialized_questions,
                "regenerated_passage": serialized_passage
            }
        else:
            # ì¬ìƒì„± ì‹¤íŒ¨
            current_task.update_state(
                state='FAILURE',
                meta={'error': message, 'status': 'ì¬ìƒì„± ì‹¤íŒ¨'}
            )
            raise Exception(message)

    except Exception as e:
        print(f"âŒ ì˜ì–´ ë¬¸ì œ ì¬ìƒì„± ì‹¤íŒ¨: {str(e)}")

        # íƒœìŠ¤í¬ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        current_task.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ë¬¸ì œ ì¬ìƒì„± ì‹¤íŒ¨'}
        )

        raise Exception(f"ì˜ì–´ ë¬¸ì œ ì¬ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")