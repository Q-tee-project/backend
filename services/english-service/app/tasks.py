from celery import current_task
from sqlalchemy.orm import Session
import json
from datetime import datetime
from typing import Dict, Any

from .celery_app import celery_app
from .database import SessionLocal
from .core.config import get_settings
from .schemas.generation import WorksheetGenerationRequest
from .schemas.regeneration import RegenerateEnglishQuestionRequest
from .services.generation.question_generator import PromptGenerator
from .services.regeneration.question_regenerator import QuestionRegenerator

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

settings = get_settings()


def get_session():
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±"""
    return SessionLocal()


@celery_app.task(bind=True, name="app.tasks.generate_english_worksheet_task")
def generate_english_worksheet_task(self, request_data: dict):
    """ì˜ì–´ ì›Œí¬ì‹œíŠ¸ ìƒì„± ë¹„ë™ê¸° íƒœìŠ¤í¬"""

    task_id = self.request.id
    print(f"ğŸš€ English worksheet generation task started: {task_id}")

    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        request = WorksheetGenerationRequest.model_validate(request_data)

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì‹œì‘ (10%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'ë¬¸ì œ ìƒì„± ì˜µì…˜ ì²˜ë¦¬ ì¤‘...'}
        )

        print("ğŸ¯ ë¬¸ì œ ìƒì„± ì˜µì…˜ ì²˜ë¦¬:")
        print(f" í•™êµê¸‰: {request.school_level}")
        print(f" í•™ë…„: {request.grade}í•™ë…„")
        print(f" ì´ ë¬¸ì œ ìˆ˜: {request.total_questions}ê°œ")
        print(f" ì„ íƒëœ ì˜ì—­: {', '.join(request.subjects)}")

        # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
        db = get_session()

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - í”„ë¡¬í”„íŠ¸ ìƒì„± (30%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 30, 'total': 100, 'status': 'í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...'}
        )

        # í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        print("ğŸ¯ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘...")
        generator = PromptGenerator()

        # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        request_dict = request.model_dump()

        # ë¶„ë°° ìš”ì•½ ìƒì„±
        distribution_summary = generator.get_distribution_summary(request_dict)

        print("ğŸ“Š ë¶„ë°° ê²°ê³¼:")
        print(f"  ì´ ë¬¸ì œ ìˆ˜: {distribution_summary['total_questions']}")
        print("  ì˜ì—­ë³„ ë¶„ë°°:")
        for item in distribution_summary['subject_distribution']:
            print(f"    {item['subject']}: {item['count']}ë¬¸ì œ ({item['ratio']}%)")

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        try:
            print("ğŸ” í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œë„ ì¤‘...")
            prompt = generator.generate_prompt(request_dict, db=db)
            print("âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ!")
        except Exception as prompt_error:
            print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {prompt_error}")
            db.close()
            raise Exception(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(prompt_error)}")

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - AI í˜¸ì¶œ (60%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 60, 'total': 100, 'status': 'AI ë¬¸ì œ ìƒì„± ì¤‘...'}
        )

        # LLMì— í”„ë¡¬í”„íŠ¸ ì „ì†¡ ë° ì‘ë‹µ ë°›ê¸°
        llm_response = None
        llm_error = None

        if GEMINI_AVAILABLE:
            try:
                print("ğŸ¤– Gemini API í˜¸ì¶œ ì‹œì‘...")

                # Gemini API í‚¤ ì„¤ì •
                if not settings.gemini_api_key:
                    raise Exception("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                genai.configure(api_key=settings.gemini_api_key)

                # Gemini ëª¨ë¸ ìƒì„±
                model = genai.GenerativeModel(settings.gemini_model)

                # í†µí•© í”„ë¡¬í”„íŠ¸ë¡œ API í•œ ë²ˆë§Œ í˜¸ì¶œ (JSON ì‘ë‹µ ìš”ì²­)
                print("ğŸ“ í†µí•© ë¬¸ì œì§€/ë‹µì•ˆì§€ ìƒì„± ì¤‘...")
                response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
                llm_response = response.text
                print("âœ… í†µí•© ìƒì„± ì™„ë£Œ!")

            except Exception as api_error:
                print(f"âŒ Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {api_error}")
                llm_error = str(api_error)
                db.close()
                raise Exception(f"AI ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(api_error)}")
        else:
            llm_error = "Gemini ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            db.close()
            raise Exception(llm_error)

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - JSON íŒŒì‹± (80%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 80, 'total': 100, 'status': 'AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘...'}
        )

        # JSON íŒŒì‹± ì²˜ë¦¬
        parsed_llm_response = None

        if llm_response:
            try:
                # í†µí•© JSON íŒŒì‹±
                parsed_llm_response = json.loads(llm_response)
                print("âœ… í†µí•© JSON íŒŒì‹± ì™„ë£Œ!")
            except json.JSONDecodeError as e:
                print(f"âš ï¸ í†µí•© JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                db.close()
                raise Exception(f"AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì™„ë£Œ (100%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 100, 'total': 100, 'status': 'ì™„ë£Œ!'}
        )

        # ë°±ì—”ë“œì—ì„œ ê²°ê³¼ ì¶œë ¥
        print("=" * 80)
        print("ğŸ‰ ë¬¸ì œì§€ ë° ë‹µì•ˆì§€ ìƒì„± ì™„ë£Œ!")
        print("=" * 80)
        if parsed_llm_response:
            print(f"ğŸ“„ ë¬¸ì œì§€ ID: {parsed_llm_response.get('worksheet_id', 'N/A')}")
            print(f"ğŸ“ ë¬¸ì œì§€ ì œëª©: {parsed_llm_response.get('worksheet_name', 'N/A')}")
            print(f"ğŸ“Š ì´ ë¬¸ì œ ìˆ˜: {parsed_llm_response.get('total_questions', 'N/A')}ê°œ")
            print(f"ğŸ” ë¬¸ì œ ìœ í˜•: {parsed_llm_response.get('problem_type', 'N/A')}")
        print("=" * 80)

        db.close()

        # ê¸°ì¡´ê³¼ ë™ì¼í•œ í˜•íƒœë¡œ ë°˜í™˜ (DB ì €ì¥í•˜ì§€ ì•ŠìŒ)
        return {
            "message": "ë¬¸ì œì§€ì™€ ë‹µì•ˆì§€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            "status": "success",
            "llm_response": parsed_llm_response,  # ìƒì„±ëœ JSONì„ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬
            "llm_error": llm_error,
        }

    except Exception as e:
        print(f"âŒ ì˜ì–´ ì›Œí¬ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

        # íƒœìŠ¤í¬ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        current_task.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ë¬¸ì œ ìƒì„± ì‹¤íŒ¨'}
        )

        raise Exception(f"ì˜ì–´ ì›Œí¬ì‹œíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")


@celery_app.task(bind=True, name="app.tasks.get_task_status")
def get_task_status(self, task_id: str):
    """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
    try:
        result = celery_app.AsyncResult(task_id)

        if result.state == 'PENDING':
            response = {
                'state': result.state,
                'status': 'ëŒ€ê¸° ì¤‘...'
            }
        elif result.state == 'PROGRESS':
            response = {
                'state': result.state,
                'current': result.info.get('current', 0),
                'total': result.info.get('total', 100),
                'status': result.info.get('status', '')
            }
        elif result.state == 'SUCCESS':
            response = {
                'state': result.state,
                'result': result.info
            }
        else:  # FAILURE
            response = {
                'state': result.state,
                'error': str(result.info)
            }

        return response

    except Exception as e:
        return {
            'state': 'FAILURE',
            'error': f'íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }


@celery_app.task(bind=True, name="app.tasks.regenerate_english_question_task")
def regenerate_english_question_task(self, request_data: dict):
    """ì˜ì–´ ë¬¸ì œ ì¬ìƒì„± ë¹„ë™ê¸° íƒœìŠ¤í¬"""

    task_id = self.request.id
    print(f"ğŸ”„ English question regeneration task started: {task_id}")

    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        request = RegenerateEnglishQuestionRequest.model_validate(request_data)

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì‹œì‘ (10%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'ì¬ìƒì„± ì˜µì…˜ ì²˜ë¦¬ ì¤‘...'}
        )

        print("ğŸ”„ ë¬¸ì œ ì¬ìƒì„± ì˜µì…˜ ì²˜ë¦¬:")
        print(f" ëŒ€ìƒ ë¬¸ì œ ìˆ˜: {len(request.questions)}ê°œ")
        print(f" ì§€ë¬¸ ì¬ìƒì„±: {'ìˆìŒ' if request.passage else 'ì—†ìŒ'}")
        print(f" ì‚¬ìš©ì í”¼ë“œë°±: {request.formData.feedback}")

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì¬ìƒì„± ì‹œì‘ (30%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 30, 'total': 100, 'status': 'ë¬¸ì œ ì¬ìƒì„± ì¤‘...'}
        )

        # ë¬¸ì œ ì¬ìƒì„±ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        print("ğŸ¯ ë¬¸ì œ ì¬ìƒì„± ì‹œì‘...")
        regenerator = QuestionRegenerator()

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - AI ì²˜ë¦¬ (60%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 60, 'total': 100, 'status': 'AI ì¬ìƒì„± ì²˜ë¦¬ ì¤‘...'}
        )

        # ì¬ìƒì„± ì‹¤í–‰
        success, message, regenerated_questions, regenerated_passage = regenerator.regenerate_from_data(
            questions=request.questions,
            passage=request.passage,
            form_data=request.formData
        )

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ê²°ê³¼ ì²˜ë¦¬ (80%)
        current_task.update_state(
            state='PROGRESS',
            meta={'current': 80, 'total': 100, 'status': 'ì¬ìƒì„± ê²°ê³¼ ì²˜ë¦¬ ì¤‘...'}
        )

        if success:
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ - ì™„ë£Œ (100%)
            current_task.update_state(
                state='PROGRESS',
                meta={'current': 100, 'total': 100, 'status': 'ì¬ìƒì„± ì™„ë£Œ!'}
            )

            # ë°±ì—”ë“œì—ì„œ ê²°ê³¼ ì¶œë ¥
            print("=" * 80)
            print("ğŸ‰ ë¬¸ì œ ì¬ìƒì„± ì™„ë£Œ!")
            print("=" * 80)
            print(f"ğŸ“ ì¬ìƒì„±ëœ ë¬¸ì œ ìˆ˜: {len(regenerated_questions) if regenerated_questions else 0}ê°œ")
            print(f"ğŸ“„ ì¬ìƒì„±ëœ ì§€ë¬¸: {'ìˆìŒ' if regenerated_passage else 'ì—†ìŒ'}")
            print("=" * 80)

            # Pydantic ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            serialized_questions = None
            if regenerated_questions:
                serialized_questions = [q.model_dump() if hasattr(q, 'model_dump') else q for q in regenerated_questions]

            serialized_passage = None
            if regenerated_passage:
                serialized_passage = regenerated_passage.model_dump() if hasattr(regenerated_passage, 'model_dump') else regenerated_passage

            return {
                "status": "success",
                "message": message,
                "regenerated_questions": serialized_questions,
                "regenerated_passage": serialized_passage
            }
        else:
            # ì¬ìƒì„± ì‹¤íŒ¨
            current_task.update_state(
                state='FAILURE',
                meta={'error': message, 'status': 'ì¬ìƒì„± ì‹¤íŒ¨'}
            )
            raise Exception(message)

    except Exception as e:
        print(f"âŒ ì˜ì–´ ë¬¸ì œ ì¬ìƒì„± ì‹¤íŒ¨: {str(e)}")

        # íƒœìŠ¤í¬ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        current_task.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ë¬¸ì œ ì¬ìƒì„± ì‹¤íŒ¨'}
        )

        raise Exception(f"ì˜ì–´ ë¬¸ì œ ì¬ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")