#!/usr/bin/env python3
"""
English Service ì „ì²´ ì´ˆê¸° ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸

data í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ìë™ìœ¼ë¡œ importí•©ë‹ˆë‹¤.
"""

import json
import os
from datetime import datetime
from sqlalchemy.orm import sessionmaker
from database import engine
from models import (
    GrammarCategory, GrammarTopic, GrammarAchievement,
    VocabularyCategory, Word, ReadingType, TextType
)

# ì„¸ì…˜ ìƒì„±
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def load_json_data(filename):
    """JSON íŒŒì¼ì„ ì½ì–´ì„œ íŒŒì´ì¬ ê°ì²´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # .json í™•ì¥ìê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¶”ê°€
    if not filename.endswith('.json'):
        filename += '.json'
    
    filepath = os.path.join("data", filename)
    if not os.path.exists(filepath):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return []
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            # vocabulary_categories íŒŒì¼ì€ {}ë¡œ ê°ì‹¸ì ¸ ìˆìŒ
            if content.startswith('{') and content.endswith('}'):
                # {} ì œê±°í•˜ê³  ë‚´ìš©ë§Œ ì¶”ì¶œ
                content = content[1:-1].strip()
            
            if content.startswith('[') and content.endswith(']'):
                return json.loads(content)
            else:
                # JSON ë°°ì—´ì´ ì•„ë‹Œ ê²½ìš° ë°°ì—´ë¡œ ê°ì‹¸ê¸°
                return json.loads(f'[{content}]')
                
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜ in {filename}: {e}")
        return []
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ in {filename}: {e}")
        return []

def init_grammar_categories(db):
    """ë¬¸ë²• ì¹´í…Œê³ ë¦¬ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if db.query(GrammarCategory).count() > 0:
        existing_count = db.query(GrammarCategory).count()
        print(f"ğŸ“š Grammar Categories: ì´ë¯¸ {existing_count}ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return
        
    data = load_json_data("grammar_categories")
    if not data:
        print("âŒ Grammar Categories: ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“š Grammar Categories ë°ì´í„° import ì‹œì‘... ({len(data)}ê°œ í•­ëª©)")
    
    for item in data:
        category = GrammarCategory(
            id=item.get("id"),
            name=item.get("name"),
            created_at=datetime.fromisoformat(item.get("created_at").replace('Z', '+00:00')) if item.get("created_at") else None
        )
        db.add(category)
        print(f"   - {item.get('name')} (ID: {item.get('id')})")
    
    db.commit()
    print(f"âœ… Grammar Categories: {len(data)}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def init_grammar_topics(db):
    """ë¬¸ë²• ì£¼ì œ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if db.query(GrammarTopic).count() > 0:
        existing_count = db.query(GrammarTopic).count()
        print(f"ğŸ“– Grammar Topics: ì´ë¯¸ {existing_count}ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return
        
    data = load_json_data("grammar_topics")
    if not data:
        print("âŒ Grammar Topics: ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“– Grammar Topics ë°ì´í„° import ì‹œì‘... ({len(data)}ê°œ í•­ëª©)")
    
    for item in data:
        topic = GrammarTopic(
            id=item.get("id"),
            category_id=item.get("category_id"),
            name=item.get("name"),
            learning_objective=item.get("learning_objective"),
            created_at=datetime.fromisoformat(item.get("created_at").replace('Z', '+00:00')) if item.get("created_at") else None
        )
        db.add(topic)
        print(f"   - {item.get('name')} (ID: {item.get('id')}, Category: {item.get('category_id')})")
    
    db.commit()
    print(f"âœ… Grammar Topics: {len(data)}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def init_grammar_achievements(db):
    """ë¬¸ë²• ì„±ì·¨ë„ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if db.query(GrammarAchievement).count() > 0:
        existing_count = db.query(GrammarAchievement).count()
        print(f"ğŸ† Grammar Achievements: ì´ë¯¸ {existing_count}ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return
        
    data = load_json_data("grammar_achievements")
    if not data:
        print("âŒ Grammar Achievements: ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ† Grammar Achievements ë°ì´í„° import ì‹œì‘... ({len(data)}ê°œ í•­ëª©)")
    
    level_counts = {}
    
    for item in data:
        achievement = GrammarAchievement(
            id=item.get("id"),
            topic_id=item.get("topic_id"),
            level=item.get("level"),
            description=item.get("description"),
            created_at=datetime.fromisoformat(item.get("created_at").replace('Z', '+00:00')) if item.get("created_at") else None
        )
        db.add(achievement)
        
        level = item.get("level", "unknown")
        level_counts[level] = level_counts.get(level, 0) + 1
        
        print(f"   - {item.get('level')}: {item.get('description')[:50]}... (Topic: {item.get('topic_id')})")
    
    db.commit()
    print(f"âœ… Grammar Achievements: {len(data)}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("   ë ˆë²¨ë³„ ë¶„í¬:")
    for level, count in sorted(level_counts.items()):
        print(f"   - {level}: {count}ê°œ")

def init_vocabulary_categories(db):
    """ì–´íœ˜ ì¹´í…Œê³ ë¦¬ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if db.query(VocabularyCategory).count() > 0:
        existing_count = db.query(VocabularyCategory).count()
        print(f"ğŸ“ Vocabulary Categories: ì´ë¯¸ {existing_count}ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return
        
    data = load_json_data("vocabulary_categories")
    if not data:
        print("âŒ Vocabulary Categories: ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ Vocabulary Categories ë°ì´í„° import ì‹œì‘... ({len(data)}ê°œ í•­ëª©)")
    
    for item in data:
        category = VocabularyCategory(
            id=item.get("id"),
            name=item.get("name"),
            learning_objective=item.get("learning_objective"),
            created_at=datetime.fromisoformat(item.get("created_at").replace('Z', '+00:00')) if item.get("created_at") else None
        )
        db.add(category)
        print(f"   - {item.get('name')} (ID: {item.get('id')})")
    
    db.commit()
    print(f"âœ… Vocabulary Categories: {len(data)}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def init_words(db):
    """ë‹¨ì–´ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if db.query(Word).count() > 0:
        existing_count = db.query(Word).count()
        print(f"ğŸ’¬ Words: ì´ë¯¸ {existing_count}ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return
        
    data = load_json_data("words")
    if not data:
        print("âŒ Words: ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ’¬ Words ë°ì´í„° import ì‹œì‘... ({len(data)}ê°œ í•­ëª©)")
    
    # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    level_counts = {}
    
    for i, item in enumerate(data):
        word = Word(
            id=item.get("id"),
            word=item.get("word"),
            level=item.get("level"),
            created_at=datetime.fromisoformat(item.get("created_at").replace('Z', '+00:00')) if item.get("created_at") else None
        )
        db.add(word)
        
        # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸ ì¦ê°€
        level = item.get("level", "unknown")
        level_counts[level] = level_counts.get(level, 0) + 1
        
        # ì²˜ìŒ 10ê°œë§Œ ê°œë³„ ì¶œë ¥, ì´í›„ëŠ” 100ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
        if i < 10:
            print(f"   - {item.get('word')} ({item.get('level')}) (ID: {item.get('id')})")
        elif (i + 1) % 100 == 0:
            print(f"   ... {i + 1}/{len(data)} ê°œ ì²˜ë¦¬ë¨")
    
    db.commit()
    
    # ë ˆë²¨ë³„ ìš”ì•½ ì¶œë ¥
    print(f"âœ… Words: {len(data)}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("   ë ˆë²¨ë³„ ë¶„í¬:")
    for level, count in sorted(level_counts.items()):
        print(f"   - {level}: {count}ê°œ")

def init_reading_types(db):
    """ë…í•´ ìœ í˜• ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if db.query(ReadingType).count() > 0:
        existing_count = db.query(ReadingType).count()
        print(f"ğŸ“š Reading Types: ì´ë¯¸ {existing_count}ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return
        
    data = load_json_data("reading_types")
    if not data:
        print("âŒ Reading Types: ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“š Reading Types ë°ì´í„° import ì‹œì‘... ({len(data)}ê°œ í•­ëª©)")
    
    for item in data:
        reading_type = ReadingType(
            id=item.get("id"),
            name=item.get("name"),
            description=item.get("description"),
            created_at=datetime.fromisoformat(item.get("created_at").replace('Z', '+00:00')) if item.get("created_at") else None
        )
        db.add(reading_type)
        print(f"   - {item.get('name')} (ID: {item.get('id')})")
        print(f"     {item.get('description')}")
    
    db.commit()
    print(f"âœ… Reading Types: {len(data)}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def init_text_types(db):
    """í…ìŠ¤íŠ¸ ìœ í˜• ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if db.query(TextType).count() > 0:
        existing_count = db.query(TextType).count()
        print(f"ğŸ“„ Text Types: ì´ë¯¸ {existing_count}ê°œ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return
        
    data = load_json_data("text_types")
    if not data:
        print("âŒ Text Types: ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“„ Text Types ë°ì´í„° import ì‹œì‘... ({len(data)}ê°œ í•­ëª©)")
    
    for item in data:
        text_type = TextType(
            id=item.get("id"),
            type_name=item.get("type_name"),
            display_name=item.get("display_name"),
            description=item.get("description"),
            json_format=item.get("json_format"),
            created_at=datetime.fromisoformat(item.get("created_at").replace('Z', '+00:00')) if item.get("created_at") else None
        )
        db.add(text_type)
        print(f"   - {item.get('display_name')} ({item.get('type_name')}) (ID: {item.get('id')})")
        print(f"     {item.get('description')}")
    
    db.commit()
    print(f"âœ… Text Types: {len(data)}ê°œ í•­ëª©ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def init_all_data():
    """ëª¨ë“  ì´ˆê¸° ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ìƒì„±í•©ë‹ˆë‹¤."""
    print("\n" + "="*80)
    print("ğŸš€ English Service ì´ˆê¸° ë°ì´í„° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("="*80)
    
    db = SessionLocal()
    
    try:
        # ìˆœì„œëŒ€ë¡œ ë°ì´í„° ì´ˆê¸°í™” (ì™¸ë˜í‚¤ ê´€ê³„ ê³ ë ¤)
        init_grammar_categories(db)
        init_grammar_topics(db)
        init_grammar_achievements(db)
        init_vocabulary_categories(db)
        init_words(db)
        init_reading_types(db)
        init_text_types(db)
        
        print("\n" + "="*80)
        print("âœ¨ ëª¨ë“  ì´ˆê¸° ë°ì´í„° ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*80)
        
    except Exception as e:
        db.rollback()
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise
    finally:
        db.close()

if __name__ == "__main__":
    init_all_data()
