import os
import json
import random
import time
import google.generativeai as genai
from typing import Dict, List, Optional, Tuple
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

from ..prompt_templates.single_problem_en import SingleProblemEnglishTemplate
from ..prompt_templates.multiple_problems_en import MultipleProblemEnglishTemplate
from .validators.ai_judge_validator import AIJudgeValidator
from .utils.retry_handler import retry_with_backoff

# .env íŒŒì¼ ë¡œë“œ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
load_dotenv()  # í˜„ì¬ ë””ë ‰í† ë¦¬
load_dotenv(os.path.join(os.path.dirname(__file__), "..", "..", "..", "..", ".env"))  # backend/.env

class KoreanProblemGenerator:
    def __init__(self):
        gemini_api_key = os.getenv("KOREAN_GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not gemini_api_key:
            raise ValueError("KOREAN_GEMINI_API_KEY or GEMINI_API_KEY environment variable is required")

        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel('gemini-2.5-pro')

        # AI Judge Validator ì´ˆê¸°í™”
        self.ai_judge_validator = AIJudgeValidator()

        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        self.data_path = os.path.join(os.path.dirname(__file__), "..", "..", "data")

        # ì˜ì–´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¸ìŠ¤í„´ìŠ¤
        self.single_template_en = SingleProblemEnglishTemplate()
        self.multiple_template_en = MultipleProblemEnglishTemplate()

    def _extract_user_specified_works(self, user_prompt: str, available_files: List[str]) -> List[str]:
        """ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì‘í’ˆë“¤ì„ ì¶”ì¶œí•˜ì—¬ í•´ë‹¹í•˜ëŠ” íŒŒì¼ë“¤ì„ ë°˜í™˜"""
        if not user_prompt:
            return []

        user_specified_files = []
        user_prompt_lower = user_prompt.lower()

        # ê° íŒŒì¼ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ì–¸ê¸‰í–ˆëŠ”ì§€ í™•ì¸
        for file_name in available_files:
            # íŒŒì¼ëª…ì—ì„œ ì œëª©ê³¼ ì‘ê°€ ì¶”ì¶œ (ì˜ˆ: "ë‚˜ë¬´-ìœ¤ë™ì£¼.txt" -> "ë‚˜ë¬´", "ìœ¤ë™ì£¼")
            title_author = file_name.replace('.txt', '')
            if '-' in title_author:
                title, author = title_author.split('-', 1)
            else:
                title, author = title_author, ""

            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì—ì„œ ì œëª©ì´ë‚˜ ì‘ê°€ê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
            title_mentioned = title.lower() in user_prompt_lower
            author_mentioned = author.lower() in user_prompt_lower if author else False

            # ì œëª©-ì‘ê°€ í˜•íƒœë¡œ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ë„ í™•ì¸ (ì˜ˆ: "ë‚˜ë¬´-ìœ¤ë™ì£¼")
            full_name_mentioned = title_author.lower() in user_prompt_lower

            if title_mentioned or author_mentioned or full_name_mentioned:
                user_specified_files.append(file_name)

        return user_specified_files

    def _preprocess_source_by_type(self, source_text: str, korean_type: str, source_info: Dict) -> str:
        """ìœ í˜•ë³„ ì§€ë¬¸ ì „ì²˜ë¦¬ - 4ê°€ì§€ ìœ í˜•ì— ë§ê²Œ ìµœì í™”"""

        if korean_type == "ì‹œ":
            return source_text[:2000] if len(source_text) > 2000 else source_text
        elif korean_type in ["ì†Œì„¤", "ìˆ˜í•„/ë¹„ë¬¸í•™"]:
            return self._extract_key_passage(source_text, korean_type) if len(source_text) > 1500 else source_text
        return source_text

    def _extract_key_passage(self, source_text: str, korean_type: str) -> str:
        """ê¸´ ì§€ë¬¸ì—ì„œ í•µì‹¬ ë¶€ë¶„ ë°œì·Œ (ìœ í˜•ë³„ ë§ì¶¤ ì˜ì–´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)"""
        try:
            # ìœ í˜•ë³„ ë°œì·Œ ê¸°ì¤€ ì„¤ì •
            type_specific_criteria = {
                "ì†Œì„¤": "Choose a passage with rich narrative content: character conflict, dialogue revealing personality, crucial plot development, or thematic significance. The passage should show character interactions or internal conflict.",
                "ìˆ˜í•„/ë¹„ë¬¸í•™": "Choose a passage containing the main argument, key evidence, or central thesis. The passage should be logically complete and contain the author's main point or important supporting details.",
            }

            criteria = type_specific_criteria.get(korean_type, "Choose the most important and representative passage.")

            # ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ ìš”ì²­
            prompt = f"""You are an expert Korean literature teacher. Extract a key passage from the following {korean_type} text that is most suitable for creating comprehension questions.

**Requirements:**
- Extract 800-1200 characters (Korean characters)
- {criteria}
- The passage should be self-contained and understandable without additional context
- Preserve the exact original text (do not modify, paraphrase, or summarize)
- Include complete sentences only (start and end with complete thoughts)

**Original Text:**
```
{source_text[:3000]}
```

Return ONLY the extracted passage in Korean (no explanations, no markdown, no JSON, just the extracted text):
"""

            response = self.model.generate_content(prompt)
            extracted_text = response.text.strip()
            if len(extracted_text) < 200:
                return source_text[:1200] + "..." if len(source_text) > 1200 else source_text
            return extracted_text
        except Exception:
            return source_text[:1200] + "..." if len(source_text) > 1200 else source_text

    def _distribute_question_types(self, count: int, question_type_ratio: Dict, korean_data: Dict) -> List[str]:
        """ë¬¸ì œ ìˆ˜ì— ë§ê²Œ ë¬¸ì œ ìœ í˜• ë¶„ë°° - êµ­ì–´ëŠ” ëª¨ë‘ ê°ê´€ì‹"""
        # êµ­ì–´ëŠ” ëª¨ë“  ë¬¸ì œë¥¼ ê°ê´€ì‹ìœ¼ë¡œ ìƒì„±
        return ['ê°ê´€ì‹'] * count

    def _distribute_difficulties(self, count: int, difficulty_ratio: Dict, korean_data: Dict) -> List[str]:
        """ë¬¸ì œ ìˆ˜ì— ë§ê²Œ ë‚œì´ë„ ë¶„ë°°"""
        if difficulty_ratio and sum(difficulty_ratio.values()) == 100:
            difficulties = list(difficulty_ratio.keys())
            weights = list(difficulty_ratio.values())
            return random.choices(difficulties, weights=weights, k=count)
        else:
            default_difficulty = korean_data.get('difficulty', 'ì¤‘')
            return [default_difficulty] * count

    def _get_rendered_source_text(self, korean_type: str, source_text: str, problem_data: Dict = None) -> str:
        """ìœ í˜•ë³„ ë Œë”ë§í•  ì§€ë¬¸ í…ìŠ¤íŠ¸ ê²°ì •"""
        if korean_type == "ë¬¸ë²•":
            if problem_data:
                llm_generated_text = problem_data.get('source_text', '')
                if llm_generated_text and llm_generated_text != source_text:
                    return llm_generated_text
            return ""
        return source_text

    def _generate_multiple_problems_from_single_text(self, source_text: str, source_info: Dict,
                                                   korean_type: str, count: int,
                                                   question_type_ratio: Dict, difficulty_ratio: Dict,
                                                   user_prompt: str, korean_data: Dict,
                                                   max_retries: int = 3) -> List[Dict]:
        """í•˜ë‚˜ì˜ ì§€ë¬¸ìœ¼ë¡œ ì—¬ëŸ¬ ë¬¸ì œë¥¼ í•œ ë²ˆì— ìƒì„± (AI Judge ì¬ê²€ì¦ ë¡œì§ í¬í•¨)"""

        # ë¬¸ì œ ìœ í˜•ê³¼ ë‚œì´ë„ ë¶„í¬ ê²°ì •
        question_types = self._distribute_question_types(count, question_type_ratio, korean_data)
        difficulties = self._distribute_difficulties(count, difficulty_ratio, korean_data)

        # ì˜ì–´ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„± (ë” ë‚˜ì€ LLM ì„±ëŠ¥)
        original_prompt = self.multiple_template_en.generate_prompt(
            source_text, source_info, korean_type, count,
            question_types, difficulties, user_prompt, korean_data
        )

        valid_problems = []  # í•©ê²©í•œ ë¬¸ì œ ëˆ„ì 
        prompt = original_prompt

        # ì¬ì‹œë„ ë¡œì§
        for attempt in range(max_retries):
            try:
                needed_count = count - len(valid_problems)
                if needed_count <= 0:
                    return valid_problems[:count]

                print(f"ğŸ”„ ë¬¸ì œ ìƒì„± ì‹œë„ {attempt + 1}/{max_retries} (í˜„ì¬ {len(valid_problems)}/{count}ê°œ ì™„ë£Œ)")

                # AI í˜¸ì¶œ ë° íŒŒì‹±
                response = self.model.generate_content(prompt)
                problems = self._parse_and_validate_problems(
                    response.text, source_text, source_info, korean_type, needed_count, difficulties
                )

                if not problems:
                    if attempt < max_retries - 1:
                        time.sleep(1)
                        continue
                    break

                # AI Judge ê²€ì¦
                print(f"  ğŸ“‹ ìƒì„±ëœ ë¬¸ì œ {len(problems)}ê°œ AI Judge ê²€ì¦ ì‹œì‘...")
                invalid_problems = []
                for idx, problem in enumerate(problems):
                    try:
                        is_valid, scores, feedback = self.ai_judge_validator.validate_problem(problem, korean_type)
                        if is_valid:
                            valid_problems.append(problem)
                            print(f"  âœ… ë¬¸ì œ ê²€ì¦ í†µê³¼ (ëˆ„ì : {len(valid_problems)}/{count}ê°œ)")
                        else:
                            print(f"  âŒ ë¬¸ì œ {idx+1} ê²€ì¦ ì‹¤íŒ¨: {feedback}")
                            invalid_problems.append({"problem": problem, "feedback": feedback, "scores": scores})
                    except Exception as e:
                        invalid_problems.append({"problem": problem, "feedback": f"ê²€ì¦ ì˜¤ë¥˜: {str(e)}", "scores": {"overall_score": 0}})

                # ëª©í‘œ ë‹¬ì„± í™•ì¸
                if len(valid_problems) >= count:
                    return valid_problems[:count]

                # ì¬ì‹œë„
                if attempt < max_retries - 1 and invalid_problems:
                    prompt = self._rebuild_korean_prompt_with_feedback(original_prompt, invalid_problems, korean_type)
                    time.sleep(1)

            except Exception as e:
                print(f"âŒ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                break

        return valid_problems if valid_problems else []

    def _parse_and_validate_problems(self, result_text: str, source_text: str,
                                     source_info: Dict, korean_type: str, count: int,
                                     difficulties: List[str]) -> List[Dict]:

        # JSON íŒŒì‹±
        try:
            if "```json" in result_text:
                json_start = result_text.find("```json") + 7
                json_end = result_text.find("```", json_start)
                json_text = result_text[json_start:json_end].strip()
            else:
                json_text = result_text.strip()

            problems_data = json.loads(json_text)

            # ë¬¸ì œ ë°ì´í„° ë³€í™˜
            problems = []
            for idx, problem_data in enumerate(problems_data.get('problems', [])):
                rendered_source_text = self._get_rendered_source_text(korean_type, source_text, problem_data)
                problem = {
                    'korean_type': korean_type,
                    'question_type': 'ê°ê´€ì‹',  # êµ­ì–´ëŠ” ëª¨ë‘ ê°ê´€ì‹
                    'difficulty': difficulties[idx] if idx < len(difficulties) else 'ì¤‘',
                    'question': problem_data.get('question', ''),
                    'correct_answer': problem_data.get('correct_answer', ''),
                    'explanation': problem_data.get('explanation', ''),
                    'source_text': rendered_source_text,
                    'source_title': source_info.get('title', ''),
                    'source_author': source_info.get('author', ''),
                    'sequence_order': idx + 1
                }

                # ê°ê´€ì‹ ì„ íƒì§€ ì¶”ê°€ (êµ­ì–´ëŠ” í•­ìƒ ê°ê´€ì‹)
                if 'choices' in problem_data:
                    problem['choices'] = problem_data['choices']

                problems.append(problem)

            return problems

        except json.JSONDecodeError as e:
            raise Exception(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        except Exception as e:
            raise Exception(f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")

    def _generate_problems_individually(self, source_text: str, source_info: Dict, korean_type: str,
                                      count: int, question_type_ratio: Dict, difficulty_ratio: Dict,
                                      user_prompt: str, korean_data: Dict) -> List[Dict]:
        """í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê°œë³„ ë¬¸ì œ ìƒì„±"""
        problems = []

        for i in range(count):
            try:
                # ë¬¸ì œ íƒ€ì… ê²°ì •
                question_type = self._determine_question_type(question_type_ratio, korean_data)

                # ë‚œì´ë„ ê²°ì •
                difficulty = self._determine_difficulty(difficulty_ratio, korean_data)

                # AIë¥¼ í†µí•œ ë¬¸ì œ ìƒì„±
                problem = self._generate_single_problem(
                    source_text, korean_type, question_type, difficulty, user_prompt, korean_data
                )

                if problem:
                    problem['sequence_order'] = i + 1
                    problem['source_title'] = source_info.get('title', '')
                    problem['source_author'] = source_info.get('author', '')
                    problems.append(problem)

            except Exception:
                continue

        return problems

    def _determine_question_type(self, question_type_ratio: Dict, korean_data: Dict) -> str:
        """ë¬¸ì œ í˜•ì‹ ê²°ì • - êµ­ì–´ëŠ” ëª¨ë‘ ê°ê´€ì‹"""
        # êµ­ì–´ëŠ” ëª¨ë“  ë¬¸ì œë¥¼ ê°ê´€ì‹ìœ¼ë¡œ ìƒì„±
        return 'ê°ê´€ì‹'

    def _determine_difficulty(self, difficulty_ratio: Dict, korean_data: Dict) -> str:
        """ë‚œì´ë„ ê²°ì •"""
        if difficulty_ratio and sum(difficulty_ratio.values()) == 100:
            # ë¹„ìœ¨ì— ë”°ë¥¸ ëœë¤ ì„ íƒ
            difficulties = list(difficulty_ratio.keys())
            weights = list(difficulty_ratio.values())
            return random.choices(difficulties, weights=weights)[0]
        else:
            return korean_data.get('difficulty', 'ì¤‘')

    def _generate_single_problem(self, source_text: str, korean_type: str, question_type: str,
                                difficulty: str, user_prompt: str, korean_data: Dict,
                                max_retries: int = 2) -> Dict:
        """ë‹¨ì¼ ë¬¸ì œ ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""

        # ì˜ì–´ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.single_template_en.generate_prompt(
            source_text, korean_type, question_type, difficulty, user_prompt, korean_data
        )

        # ì¬ì‹œë„ ë¡œì§
        for attempt in range(max_retries):
            try:
                # AI í˜¸ì¶œ
                response = self.model.generate_content(prompt)
                result_text = response.text

                # ë¬¸ì œ íŒŒì‹± ì‹œë„
                problem = self._parse_single_problem(result_text, source_text, korean_type)

                if problem:
                    return problem
                if attempt < max_retries - 1:
                    time.sleep(1)
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(1)
                else:
                    raise
        raise Exception("ë‹¨ì¼ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨")

    def _parse_single_problem(self, result_text: str, source_text: str, korean_type: str) -> Optional[Dict]:
        """ë‹¨ì¼ ë¬¸ì œ JSON íŒŒì‹±"""
        try:

            # JSON íŒŒì‹±
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                if "```json" in result_text:
                    json_start = result_text.find("```json") + 7
                    json_end = result_text.find("```", json_start)
                    json_text = result_text[json_start:json_end].strip()
                else:
                    json_text = result_text.strip()

                problem_data = json.loads(json_text)
                rendered_source_text = self._get_rendered_source_text(korean_type, source_text, problem_data)
                problem = {
                    'korean_type': korean_type,
                    'question_type': 'ê°ê´€ì‹',  # êµ­ì–´ëŠ” ëª¨ë‘ ê°ê´€ì‹
                    'difficulty': problem_data.get('difficulty', 'ì¤‘'),
                    'question': problem_data.get('question', ''),
                    'correct_answer': problem_data.get('correct_answer', ''),
                    'explanation': problem_data.get('explanation', ''),
                    'source_text': rendered_source_text,
                    'source_title': problem_data.get('source_title', ''),
                    'source_author': problem_data.get('source_author', '')
                }

                # ê°ê´€ì‹ ì„ íƒì§€ ì¶”ê°€ (êµ­ì–´ëŠ” í•­ìƒ ê°ê´€ì‹)
                if 'choices' in problem_data:
                    problem['choices'] = problem_data['choices']

                return problem

            except json.JSONDecodeError:
                return None
        except Exception:
            return None

    def generate_problems(self, korean_data: Dict, user_prompt: str, problem_count: int = 1,
                         korean_type_ratio: Dict = None, question_type_ratio: Dict = None,
                         difficulty_ratio: Dict = None) -> List[Dict]:
        """êµ­ì–´ ë¬¸ì œ ìƒì„± - ë‹¨ì¼ ë„ë©”ì¸ ì „ìš©"""
        try:
            # ë‹¨ì¼ ìœ í˜• ë¬¸ì œ ìƒì„± (ê°œí¸ëœ ë²„ì „)
            korean_type = korean_data.get('korean_type', 'ì‹œ')
            problems = self._generate_problems_by_single_domain(
                korean_data, user_prompt, problem_count, korean_type,
                question_type_ratio, difficulty_ratio
            )

            return problems[:problem_count]  # ì •í™•í•œ ê°œìˆ˜ë¡œ ì œí•œ

        except Exception:
            return []

    def _generate_problems_by_single_domain(self, korean_data: Dict, user_prompt: str, count: int,
                                          korean_type: str, question_type_ratio: Dict = None,
                                          difficulty_ratio: Dict = None) -> List[Dict]:
        """ê°œí¸ëœ ë‹¨ì¼ ë„ë©”ì¸ ë¬¸ì œ ìƒì„±"""
        problems = []

        if korean_type == "ë¬¸ë²•":
            # ë¬¸ë²• ì˜ì—­ì€ íŠ¹ë³„ ì²˜ë¦¬
            problems = self._generate_grammar_problems(
                korean_data, user_prompt, count, question_type_ratio, difficulty_ratio
            )
        else:
            # ì‹œ, ì†Œì„¤, ìˆ˜í•„/ë¹„ë¬¸í•™ ì²˜ë¦¬
            source_texts_info = self._load_multiple_sources_for_single_domain(
                korean_type, user_prompt, count
            )

            if not source_texts_info:
                return []

            problems_per_work = count // len(source_texts_info)
            remaining_problems = count % len(source_texts_info)

            for i, (source_text, source_info) in enumerate(source_texts_info):
                work_problem_count = problems_per_work + (1 if i < remaining_problems else 0)
                if work_problem_count > 0:
                    if korean_type == "ì†Œì„¤" and len(source_text) > 1000:
                        source_text = self._extract_key_passage(source_text, korean_type)
                    try:
                        work_problems = self._generate_multiple_problems_from_single_text(
                            source_text, source_info, korean_type, work_problem_count,
                            question_type_ratio, difficulty_ratio, user_prompt, korean_data
                        )
                        problems.extend(work_problems)
                    except Exception:
                        try:
                            work_problems = self._generate_problems_individually(
                                source_text, source_info, korean_type, work_problem_count,
                                question_type_ratio, difficulty_ratio, user_prompt, korean_data
                            )
                            problems.extend(work_problems)
                        except Exception:
                            continue

        return problems

    def _load_multiple_sources_for_single_domain(self, korean_type: str, user_prompt: str,
                                               problem_count: int) -> List[tuple]:
        """ë‹¨ì¼ ë„ë©”ì¸ì— ë§ëŠ” ì‘í’ˆ ìˆ˜ ì„ íƒ"""
        try:
            # ë¬¸í•­ ìˆ˜ì— ë”°ë¥¸ ì‘í’ˆ ìˆ˜ ê²°ì •
            if problem_count <= 10:
                if korean_type == "ì‹œ":
                    work_count = 3
                elif korean_type == "ì†Œì„¤":
                    work_count = 2
                elif korean_type == "ìˆ˜í•„/ë¹„ë¬¸í•™":
                    work_count = 2
            elif problem_count <= 20:
                if korean_type == "ì‹œ":
                    work_count = 6
                elif korean_type == "ì†Œì„¤":
                    work_count = 4
                elif korean_type == "ìˆ˜í•„/ë¹„ë¬¸í•™":
                    work_count = 4
            else:
                # 20ë¬¸ì œ ì´ˆê³¼ ì‹œ ê¸°ë³¸ê°’
                work_count = min(problem_count // 3, 10)

            # í•´ë‹¹ ìœ í˜•ì˜ ëª¨ë“  íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            if korean_type == "ì‹œ":
                data_dir = os.path.join(self.data_path, "poem")
                all_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]
            elif korean_type == "ì†Œì„¤":
                data_dir = os.path.join(self.data_path, "novel")
                all_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]
            elif korean_type == "ìˆ˜í•„/ë¹„ë¬¸í•™":
                data_dir = os.path.join(self.data_path, "non-fiction")
                all_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]
            else:
                return []

            # ì‚¬ìš©ìê°€ íŠ¹ì • ì‘í’ˆì„ ì–¸ê¸‰í–ˆëŠ”ì§€ í™•ì¸
            user_specified_files = self._extract_user_specified_works(user_prompt, all_files)

            if user_specified_files:
                selected_files = user_specified_files[:work_count]
            else:
                import secrets
                if len(all_files) <= work_count:
                    selected_files = all_files
                else:
                    selected_files = []
                    available_files = all_files.copy()
                    for _ in range(work_count):
                        if not available_files:
                            break
                        random_index = secrets.randbelow(len(available_files))
                        selected_files.append(available_files.pop(random_index))

            # ì„ íƒëœ íŒŒì¼ë“¤ì˜ ë‚´ìš©ê³¼ ì •ë³´ ë¡œë“œ
            source_texts_info = []
            for file_name in selected_files:
                file_path = os.path.join(data_dir, file_name)
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # íŒŒì¼ëª…ì—ì„œ ì œëª©ê³¼ ì‘ê°€ ì¶”ì¶œ
                title_author = file_name.replace('.txt', '')
                if '-' in title_author:
                    title, author = title_author.split('-', 1)
                else:
                    title, author = title_author, "ì‘ìë¯¸ìƒ"

                source_texts_info.append((content, {
                    "title": title,
                    "author": author,
                    "file": file_name
                }))
            return source_texts_info
        except Exception:
            return []

    def _generate_grammar_problems(self, korean_data: Dict, user_prompt: str, count: int,
                                 question_type_ratio: Dict = None,
                                 difficulty_ratio: Dict = None) -> List[Dict]:
        """ë¬¸ë²• ì˜ì—­ ë¬¸ì œ ìƒì„± - I~V ì˜ì—­ë³„ ë¶„ë°°"""
        problems = []

        try:
            # ì „ì²´ ë¬¸ë²• ë‚´ìš© ë¡œë“œ
            grammar_file_path = os.path.join(self.data_path, "grammar.txt")
            with open(grammar_file_path, 'r', encoding='utf-8') as f:
                full_grammar_content = f.read()

            grammar_sections = self._split_grammar_content(full_grammar_content)
            if not grammar_sections:
                return []

            problems_per_section = count // len(grammar_sections)
            remaining_problems = count % len(grammar_sections)
            section_names = ["I. ìŒìš´", "II. í’ˆì‚¬ì™€ ì–´íœ˜", "III. ë¬¸ì¥", "IV. ê¸°íƒ€", "V. ë¶€ë¡"]

            for i, (section_name, section_content) in enumerate(zip(section_names, grammar_sections)):
                if not section_content.strip():
                    continue
                section_problem_count = problems_per_section + (1 if i < remaining_problems else 0)
                if section_problem_count > 0:
                    try:
                        section_problems = self._generate_multiple_problems_from_single_text(
                            section_content,
                            {"title": section_name, "author": "êµìœ¡ë¶€", "file": "grammar.txt"},
                            "ë¬¸ë²•", section_problem_count,
                            question_type_ratio, difficulty_ratio, user_prompt, korean_data
                        )
                        problems.extend(section_problems)
                    except Exception:
                        try:
                            section_problems = self._generate_problems_individually(
                                section_content,
                                {"title": section_name, "author": "êµìœ¡ë¶€", "file": "grammar.txt"},
                                "ë¬¸ë²•", section_problem_count,
                                question_type_ratio, difficulty_ratio, user_prompt, korean_data
                            )
                            problems.extend(section_problems)
                        except Exception:
                            continue
            return problems
        except Exception:
            return []

    def _split_grammar_content(self, content: str) -> List[str]:
        """ë¬¸ë²• ë‚´ìš©ì„ I~V ì˜ì—­ë³„ë¡œ ë¶„í• """
        try:
            sections = []
            lines = content.split('\n')
            current_section = []

            section_markers = ["I. ìŒìš´", "II. í’ˆì‚¬ì™€ ì–´íœ˜", "III. ë¬¸ì¥", "IV. ê¸°íƒ€", "V. ë¶€ë¡"]
            current_section_index = -1

            for line in lines:
                # ìƒˆë¡œìš´ ì„¹ì…˜ ì‹œì‘ í™•ì¸
                for i, marker in enumerate(section_markers):
                    if line.strip().startswith(marker):
                        # ì´ì „ ì„¹ì…˜ ì €ì¥
                        if current_section_index >= 0 and current_section:
                            sections.append('\n'.join(current_section))

                        # ìƒˆ ì„¹ì…˜ ì‹œì‘
                        current_section = [line]
                        current_section_index = i
                        break
                else:
                    # í˜„ì¬ ì„¹ì…˜ì— ë¼ì¸ ì¶”ê°€
                    if current_section_index >= 0:
                        current_section.append(line)

            # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
            if current_section_index >= 0 and current_section:
                sections.append('\n'.join(current_section))

            return sections
        except Exception:
            return []

    # ========== ë³‘ë ¬ ì²˜ë¦¬ ë©”ì„œë“œ ==========

    def generate_problems_parallel(self, korean_data: Dict, user_prompt: str, problem_count: int,
                                   difficulty_ratio: Dict = None, max_workers: int = 5) -> List[Dict]:
        """ë³‘ë ¬ë¡œ ë¬¸ì œ ìƒì„±"""

        korean_type = korean_data.get('korean_type', 'ì‹œ')
        problems = []

        if korean_type == "ë¬¸ë²•":
            # ë¬¸ë²•ì€ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            return self._generate_grammar_problems(
                korean_data, user_prompt, problem_count, None, difficulty_ratio
            )

        # ì‹œ, ì†Œì„¤, ìˆ˜í•„/ë¹„ë¬¸í•™ - ë³‘ë ¬ ì²˜ë¦¬
        source_texts_info = self._load_multiple_sources_for_single_domain(
            korean_type, user_prompt, problem_count
        )

        if not source_texts_info:
            return []

        # ê° ì‘í’ˆë³„ë¡œ ë¬¸ì œ ìˆ˜ ë¶„ë°°
        problems_per_work = problem_count // len(source_texts_info)
        remaining_problems = problem_count % len(source_texts_info)

        # ë³‘ë ¬ ì‘ì—… ë¦¬ìŠ¤íŠ¸ ìƒì„±
        tasks = []
        for i, (source_text, source_info) in enumerate(source_texts_info):
            work_problem_count = problems_per_work + (1 if i < remaining_problems else 0)

            if work_problem_count > 0:
                # ìœ í˜•ë³„ ì§€ë¬¸ ì „ì²˜ë¦¬
                processed_text = self._preprocess_source_by_type(source_text, korean_type, source_info)

                tasks.append({
                    'source_text': processed_text,
                    'source_info': source_info,
                    'count': work_problem_count,
                    'work_index': i
                })

        with ThreadPoolExecutor(max_workers=min(len(tasks), max_workers)) as executor:
            future_to_task = {}
            for task in tasks:
                future = executor.submit(
                    self._generate_problems_for_work_parallel,
                    task['source_text'],
                    task['source_info'],
                    korean_type,
                    task['count'],
                    difficulty_ratio,
                    user_prompt,
                    korean_data
                )
                future_to_task[future] = task

            for future in as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    work_problems = future.result()
                    problems.extend(work_problems)
                except Exception as e:
                    print(f"âŒ ì‘í’ˆ '{task['source_info'].get('title', 'Unknown')}' ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return problems[:problem_count]  # ì •í™•í•œ ê°œìˆ˜ë¡œ ì œí•œ

    def _generate_problems_for_work_parallel(self, source_text: str, source_info: Dict,
                                            korean_type: str, count: int,
                                            difficulty_ratio: Dict, user_prompt: str,
                                            korean_data: Dict) -> List[Dict]:
        """í•˜ë‚˜ì˜ ì‘í’ˆì— ëŒ€í•´ ë¬¸ì œë¥¼ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
        try:
            return self._generate_multiple_problems_from_single_text(
                source_text, source_info, korean_type, count,
                None, difficulty_ratio, user_prompt, korean_data
            )
        except Exception:
            return self._generate_problems_individually(
                source_text, source_info, korean_type, count,
                None, difficulty_ratio, user_prompt, korean_data
            )

    def _rebuild_korean_prompt_with_feedback(self, original_prompt: str, invalid_problems: List[Dict], korean_type: str) -> str:
        """í”¼ë“œë°±ì„ í¬í•¨í•œ êµ­ì–´ í”„ë¡¬í”„íŠ¸ ì¬êµ¬ì„±"""

        feedback_text = "\n\n**IMPORTANT: Previous attempt had validation failures. Fix these issues:**\n"

        for idx, item in enumerate(invalid_problems):
            feedback_text += f"\nProblem {idx+1} feedback:\n"
            scores = item.get('scores', {})

            # êµ­ì–´ ìœ í˜•ë³„ ì ìˆ˜ í‘œì‹œ
            if korean_type == "ì‹œ":
                feedback_text += f"- Scores: literary_accuracy={scores.get('literary_accuracy', 0):.1f}, "
                feedback_text += f"relevance={scores.get('relevance', 0):.1f}, "
                feedback_text += f"figurative_language_analysis={scores.get('figurative_language_analysis', 0):.1f}, "
                feedback_text += f"answer_clarity={scores.get('answer_clarity', 0):.1f}\n"
            elif korean_type == "ì†Œì„¤":
                feedback_text += f"- Scores: narrative_comprehension={scores.get('narrative_comprehension', 0):.1f}, "
                feedback_text += f"relevance={scores.get('relevance', 0):.1f}, "
                feedback_text += f"textual_analysis={scores.get('textual_analysis', 0):.1f}, "
                feedback_text += f"answer_clarity={scores.get('answer_clarity', 0):.1f}\n"
            elif korean_type == "ìˆ˜í•„/ë¹„ë¬¸í•™":
                feedback_text += f"- Scores: argument_comprehension={scores.get('argument_comprehension', 0):.1f}, "
                feedback_text += f"relevance={scores.get('relevance', 0):.1f}, "
                feedback_text += f"critical_thinking={scores.get('critical_thinking', 0):.1f}, "
                feedback_text += f"answer_clarity={scores.get('answer_clarity', 0):.1f}\n"
            elif korean_type == "ë¬¸ë²•":
                feedback_text += f"- Scores: grammar_accuracy={scores.get('grammar_accuracy', 0):.1f}, "
                feedback_text += f"example_quality={scores.get('example_quality', 0):.1f}, "
                feedback_text += f"explanation_clarity={scores.get('explanation_clarity', 0):.1f}, "
                feedback_text += f"answer_clarity={scores.get('answer_clarity', 0):.1f}\n"

            feedback_text += f"- Issue: {item.get('feedback', 'No feedback')}\n"

        feedback_text += "\n**MUST ensure**: All scores >= 3.5, answer_clarity >= 4.0, relevance to source text\n"

        return original_prompt + feedback_text