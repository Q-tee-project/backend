"""
OCR ì„œë¹„ìŠ¤ ë¡œì§ ë¶„ë¦¬ - ìˆ˜í•™ í•„ê¸°ì²´ ë‹µì•ˆ ì¸ì‹ ìµœì í™”
"""
import os
import requests
import base64
from typing import Dict, Optional
import io
import re

try:
    from PIL import Image, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    

try:
    import numpy as np
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    


class OCRService:
    """OCR ì „ìš© í´ë˜ìŠ¤ - ìˆ˜í•™ í•„ê¸°ì²´ ë‹µì•ˆ ì¸ì‹ì— íŠ¹í™”"""

    def __init__(self):
        self.vision_api_key = os.getenv("GOOGLE_VISION_API_KEY")
        if not self.vision_api_key:
            raise ValueError("GOOGLE_VISION_API_KEY environment variable is required")

        # ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
        self.debug_mode = os.getenv("OCR_DEBUG_MODE", "false").lower() == "true"
        self.debug_dir = os.getenv("OCR_DEBUG_DIR", "/tmp")

    def _log(self, message: str):
        """ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥"""
        if self.debug_mode:
            print(f"ğŸ” OCR: {message}")

    def extract_text_from_image(self, image_data: bytes) -> str:
        """
        Google Visionì„ ì´ìš©í•œ í•„ê¸°ì²´ OCR

        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„° (PNG, JPG ë“±)

        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸ (ìˆ˜í•™ ë‹µì•ˆ í˜•ì‹)
        """
        try:
            self._log(f"image_data íƒ€ì…: {type(image_data)}, í¬ê¸°: {len(image_data) if image_data else 0} bytes")

            if not image_data or len(image_data) < 50:
                self._log(f"ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì‘ìŒ")
                return ""

            # ë””ë²„ê·¸ ëª¨ë“œ: ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
            if self.debug_mode:
                self._save_debug_image(image_data, "original")

            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_data = self._preprocess_image(image_data)
            if processed_data:
                image_data = processed_data
                if self.debug_mode:
                    self._save_debug_image(image_data, "processed")

            # Google Vision API í˜¸ì¶œ
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            result = self._call_vision_api(image_base64)

            if result:
                self._log(f"ì›ë³¸ ì¸ì‹ í…ìŠ¤íŠ¸: {result[:100]}")
                cleaned_text = self._clean_math_text(result)
                self._log(f"í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸: {cleaned_text[:100]}")
                return cleaned_text

            return ""

        except Exception as e:
            print(f"âŒ OCR ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            if self.debug_mode:
                import traceback
                print(traceback.format_exc())
            return ""

    def _save_debug_image(self, image_data: bytes, suffix: str):
        """ë””ë²„ê·¸ìš© ì´ë¯¸ì§€ ì €ì¥"""
        try:
            import time
            timestamp = int(time.time() * 1000)
            debug_path = f"{self.debug_dir}/ocr_{suffix}_{timestamp}.png"
            with open(debug_path, 'wb') as f:
                f.write(image_data)
            self._log(f"ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥: {debug_path}")
        except Exception as e:
            self._log(f"ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _call_vision_api(self, image_base64: str) -> Optional[str]:
        """
        Google Vision API REST í˜¸ì¶œ
        - DOCUMENT_TEXT_DETECTION: í•„ê¸°ì²´ ì¸ì‹ì— ìµœì í™”
        - ì–¸ì–´ íŒíŠ¸ ì œê±°: ìˆ«ìì™€ ìˆ˜í•™ ê¸°í˜¸ ì¸ì‹ ê°œì„ 
        """
        try:
            url = f"https://vision.googleapis.com/v1/images:annotate?key={self.vision_api_key}"

            payload = {
                "requests": [
                    {
                        "image": {
                            "content": image_base64
                        },
                        "features": [
                            {
                                "type": "DOCUMENT_TEXT_DETECTION",
                                "maxResults": 10
                            }
                        ]
                        # ì–¸ì–´ íŒíŠ¸ ì œê±° - ìˆ«ìì™€ ìˆ˜í•™ ê¸°í˜¸ëŠ” ì–¸ì–´ ë…ë¦½ì 
                    }
                ]
            }

            self._log("Google Vision API í˜¸ì¶œ ì‹œì‘")
            response = requests.post(url, json=payload, headers={'Content-Type': 'application/json'}, timeout=30)
            self._log(f"ì‘ë‹µ ìƒíƒœì½”ë“œ: {response.status_code}")

            if response.status_code != 200:
                print(f"âŒ Vision API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                return None

            result = response.json()

            if 'responses' in result and result['responses']:
                response_data = result['responses'][0]

                # DOCUMENT_TEXT_DETECTION ê²°ê³¼ í™•ì¸
                if 'fullTextAnnotation' in response_data:
                    text = response_data['fullTextAnnotation'].get('text', '').strip()
                    if text:
                        return text

                # TEXT_DETECTION fallback
                if 'textAnnotations' in response_data and response_data['textAnnotations']:
                    text = response_data['textAnnotations'][0]['description'].strip()
                    if text:
                        return text

                self._log("í…ìŠ¤íŠ¸ ì¸ì‹ ê²°ê³¼ ì—†ìŒ")

            return None

        except requests.RequestException as e:
            print(f"âŒ Vision API ìš”ì²­ ì˜¤ë¥˜: {str(e)}")
            return None
        except Exception as e:
            print(f"âŒ Vision API ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return None

    def _preprocess_image(self, image_data: bytes) -> Optional[bytes]:
        """
        í•„ê¸°ì²´ ìˆ˜í•™ ë‹µì•ˆ ì¸ì‹ì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        - OpenCV ìš°ì„  ì‚¬ìš© (ë” ê°•ë ¥í•œ ì „ì²˜ë¦¬)
        - PIL fallback
        """
        if CV2_AVAILABLE:
            return self._preprocess_with_cv2(image_data)
        elif PIL_AVAILABLE:
            return self._preprocess_with_pil(image_data)
        else:
            self._log("ì „ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ì›ë³¸ ì‚¬ìš©")
            return None

    def _preprocess_with_cv2(self, image_data: bytes) -> Optional[bytes]:
        """OpenCVë¥¼ ì´ìš©í•œ ê³ ê¸‰ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # bytes -> numpy array
            nparr = np.frombuffer(image_data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if img is None:
                self._log("OpenCV ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
                return None

            self._log(f"ì›ë³¸ í¬ê¸°: {img.shape}")

            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # 2. í¬ê¸° ì¡°ì • (ì‘ì€ ì´ë¯¸ì§€ëŠ” í™•ëŒ€)
            h, w = gray.shape
            min_size = 1000
            if h < min_size or w < min_size:
                scale = max(min_size / h, min_size / w, 3.0)
                new_h, new_w = int(h * scale), int(w * scale)
                gray = cv2.resize(gray, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
                self._log(f"í¬ê¸° í™•ëŒ€: {w}x{h} â†’ {new_w}x{new_h} (x{scale:.1f})")

            # 3. ë…¸ì´ì¦ˆ ì œê±°
            denoised = cv2.fastNlMeansDenoising(gray, None, h=10, templateWindowSize=7, searchWindowSize=21)

            # 4. ëŒ€ë¹„ í–¥ìƒ (CLAHE - Contrast Limited Adaptive Histogram Equalization)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(denoised)

            # 5. ì„ ëª…í™”
            kernel = np.array([[-1, -1, -1],
                               [-1,  9, -1],
                               [-1, -1, -1]])
            sharpened = cv2.filter2D(enhanced, -1, kernel)

            # 6. Adaptive Thresholding (í•„ê¸°ì²´ ê°•ì¡°)
            binary = cv2.adaptiveThreshold(
                sharpened,
                255,
                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY,
                11,
                2
            )

            # 7. ëª¨í´ë¡œì§€ ì—°ì‚° (í•„ê¸° ì„  ì—°ê²°)
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
            morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

            # numpy array -> bytes (PNG)
            success, buffer = cv2.imencode('.png', morph, [cv2.IMWRITE_PNG_COMPRESSION, 0])
            if not success:
                self._log("OpenCV ì¸ì½”ë”© ì‹¤íŒ¨")
                return None

            processed_data = buffer.tobytes()
            self._log(f"OpenCV ì „ì²˜ë¦¬ ì™„ë£Œ: {len(image_data)} â†’ {len(processed_data)} bytes")
            return processed_data

        except Exception as e:
            self._log(f"OpenCV ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def _preprocess_with_pil(self, image_data: bytes) -> Optional[bytes]:
        """PILì„ ì´ìš©í•œ ê¸°ë³¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (fallback)"""
        try:
            image = Image.open(io.BytesIO(image_data))
            self._log(f"ì›ë³¸ í¬ê¸°: {image.size}, ëª¨ë“œ: {image.mode}")

            # RGB ë³€í™˜
            if image.mode == 'RGBA':
                white_bg = Image.new('RGB', image.size, (255, 255, 255))
                white_bg.paste(image, mask=image.split()[-1])
                image = white_bg
            elif image.mode != 'RGB':
                image = image.convert('RGB')

            # í¬ê¸° ì¡°ì •
            w, h = image.size
            min_size = 1000
            if w < min_size or h < min_size:
                scale = max(min_size / w, min_size / h, 3.0)
                new_w, new_h = int(w * scale), int(h * scale)
                image = image.resize((new_w, new_h), Image.Resampling.LANCZOS)
                self._log(f"í¬ê¸° í™•ëŒ€: {w}x{h} â†’ {new_w}x{new_h}")

            # ëŒ€ë¹„, ì„ ëª…ë„ í–¥ìƒ
            image = ImageEnhance.Contrast(image).enhance(2.0)
            image = ImageEnhance.Sharpness(image).enhance(2.0)
            image = ImageEnhance.Brightness(image).enhance(1.1)

            # PNGë¡œ ì €ì¥
            buffer = io.BytesIO()
            image.save(buffer, format='PNG', quality=100)
            processed_data = buffer.getvalue()

            self._log(f"PIL ì „ì²˜ë¦¬ ì™„ë£Œ: {len(image_data)} â†’ {len(processed_data)} bytes")
            return processed_data

        except Exception as e:
            self._log(f"PIL ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def _clean_math_text(self, text: str) -> str:
        """
        ìˆ˜í•™ ë‹µì•ˆ í…ìŠ¤íŠ¸ ì •ë¦¬
        - ë¹„ASCII ë¬¸ì ì œê±° (í•œê¸€, ì¼ë³¸ì–´ ë“±)
        - ë¶„ìˆ˜ íŒ¨í„´ ì¸ì‹
        - ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ì¸ì‹ ìˆ˜ì •
        """
        if not text or not text.strip():
            return ""

        cleaned = text.strip()
        original = cleaned

        # 1. ë¹„ASCII ë¬¸ì ì œê±° (ìˆ˜í•™ ë‹µì•ˆì€ ASCIIë§Œ í•„ìš”)
        cleaned = re.sub(r'[^\x00-\x7F]', '', cleaned)

        # 2. ë¶„ìˆ˜ íŒ¨í„´ ê°ì§€
        fraction = self._detect_fraction(cleaned)
        if fraction:
            self._log(f"ë¶„ìˆ˜ ì¸ì‹: '{original}' â†’ '{fraction}'")
            return fraction

        # 3. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ì¸ì‹ ìˆ˜ì •
        cleaned = self._fix_ocr_errors(cleaned)

        # 4. ê³µë°± ì •ë¦¬
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()

        if cleaned != original:
            self._log(f"í…ìŠ¤íŠ¸ ì •ë¦¬: '{original}' â†’ '{cleaned}'")

        return cleaned

    def _detect_fraction(self, text: str) -> Optional[str]:
        """ë¶„ìˆ˜ íŒ¨í„´ ê°ì§€"""
        # íŒ¨í„´ 1: "17\n4" (ì„¸ë¡œ ë¶„ìˆ˜)
        match = re.search(r'^(\d+)\s*[\n\r]+\s*(\d+)$', text)
        if match:
            return f"{match.group(1)}/{match.group(2)}"

        # íŒ¨í„´ 2: "17/4" (ìŠ¬ë˜ì‹œ ë¶„ìˆ˜)
        match = re.search(r'^(\d+)\s*/\s*(\d+)$', text)
        if match:
            return f"{match.group(1)}/{match.group(2)}"

        # íŒ¨í„´ 3: "17 4" (ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ë‘ ìˆ«ì)
        match = re.search(r'^(\d+)\s+(\d+)$', text)
        if match:
            return f"{match.group(1)}/{match.group(2)}"

        # íŒ¨í„´ 4: ë¬¸ìì™€ ìˆ«ì í˜¼í•© (ì˜ˆ: "E17" â†’ "1/7")
        if re.search(r'[A-Za-z]', text):
            numbers = re.findall(r'\d+', text)
            if len(numbers) == 2:
                return f"{numbers[0]}/{numbers[1]}"
            elif len(numbers) == 1 and len(numbers[0]) == 2:
                # "17" in "E17" â†’ "1/7"
                return f"{numbers[0][0]}/{numbers[0][1]}"

        return None

    def _fix_ocr_errors(self, text: str) -> str:
        """
        ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ OCR ì˜¤ì¸ì‹ ìˆ˜ì •
        - ì™„ì „ ë§¤ì¹­ì´ ì•„ë‹Œ íŒ¨í„´ ê¸°ë°˜
        """
        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°ëŠ” ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
        if re.match(r'^[\d\s\-+*/().=]+$', text):
            return text

        # ë¬¸ìê°€ ì„ì¸ ê²½ìš°ì—ë§Œ ìˆ˜ì •
        replacements = {
            r'\bl\b': '1',      # ë‹¨ì–´ ê²½ê³„ì˜ ì†Œë¬¸ì l
            r'\bI\b': '1',      # ë‹¨ì–´ ê²½ê³„ì˜ ëŒ€ë¬¸ì I
            r'\bO\b': '0',      # ë‹¨ì–´ ê²½ê³„ì˜ ëŒ€ë¬¸ì O
            r'\bS\b': '5',      # ë‹¨ì–´ ê²½ê³„ì˜ S
            r'Â§': '5',          # íŠ¹ìˆ˜ ë¬¸ì
        }

        for pattern, replacement in replacements.items():
            text = re.sub(pattern, replacement, text)

        return text

    def extract_answer_from_text(self, ocr_text: str, problem_id: int, problem_number: int) -> str:
        """
        OCR í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ë¬¸ì œì˜ ë‹µì•ˆ ì¶”ì¶œ

        Args:
            ocr_text: ì „ì²´ OCR í…ìŠ¤íŠ¸
            problem_id: ë¬¸ì œ ID
            problem_number: ë¬¸ì œ ë²ˆí˜¸

        Returns:
            ì¶”ì¶œëœ ë‹µì•ˆ
        """
        if not ocr_text:
            return ""

        lines = ocr_text.split('\n')

        # ë¬¸ì œ ë²ˆí˜¸ë¡œ ë‹µì•ˆ ì°¾ê¸°
        for i, line in enumerate(lines):
            # "1.", "1)", "1:" ë“±ì˜ íŒ¨í„´
            pattern = rf'\b{problem_number}[\.\):]\s*(.+)'
            match = re.search(pattern, line)
            if match:
                answer = match.group(1).strip()
                self._log(f"ë¬¸ì œ {problem_number} ë‹µì•ˆ ì¶”ì¶œ: {answer}")
                return answer

        # íŒ¨í„´ì„ ëª» ì°¾ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
        return ocr_text.strip()
