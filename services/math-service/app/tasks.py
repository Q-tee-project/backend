from celery import current_task
from .celery_app import celery_app
from .database import SessionLocal
from .services.math_generation_service import MathGenerationService
from .schemas.math_generation import MathProblemGenerationRequest
from .models.worksheet import Worksheet, WorksheetStatus
from .models.math_generation import MathProblemGeneration
from .models.problem import Problem
import json
import uuid
from datetime import datetime
from sqlalchemy.orm import Session


@celery_app.task(bind=True, name="app.tasks.generate_math_problems_task", soft_time_limit=30, time_limit=40)
def generate_math_problems_task(self, request_data: dict, user_id: int):
    """ë¹„ë™ê¸° ìˆ˜í•™ ë¬¸ì œ ìƒì„± íƒœìŠ¤í¬"""
    
    # íƒœìŠ¤í¬ ID ìƒì„±
    task_id = self.request.id
    generation_id = str(uuid.uuid4())
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
    db = SessionLocal()
    
    try:
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 0, 'total': 100, 'status': 'ë¬¸ì œ ìƒì„± ì¤€ë¹„ ì¤‘...'}
        )
        
        # ìš”ì²­ ë°ì´í„°ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        request = MathProblemGenerationRequest.model_validate(request_data)
        
        # ì›Œí¬ì‹œíŠ¸ ì´ˆê¸° ìƒì„± (PROCESSING ìƒíƒœ)
        worksheet_title = f"{request.chapter.chapter_name} - {request.problem_count.value}"
        worksheet = Worksheet(
            title=worksheet_title,
            school_level=request.school_level.value,
            grade=request.grade,
            semester=request.semester.value,
            unit_number=request.unit_number,
            unit_name=request.chapter.unit_name,
            chapter_number=request.chapter.chapter_number,
            chapter_name=request.chapter.chapter_name,
            problem_count=request.problem_count.value_int,
            difficulty_ratio=request.difficulty_ratio.model_dump(),
            problem_type_ratio=request.problem_type_ratio.model_dump(),
            user_prompt=request.user_text,
            generation_id=generation_id,
            status=WorksheetStatus.PROCESSING,
            teacher_id=user_id,
            created_by=user_id,
            celery_task_id=task_id
        )
        
        db.add(worksheet)
        db.flush()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 20, 'total': 100, 'status': 'êµìœ¡ê³¼ì • ë°ì´í„° ë¡œë“œ ì¤‘...'}
        )
        
        # MathGenerationService ì´ˆê¸°í™”
        math_service = MathGenerationService()
        
        # êµìœ¡ê³¼ì • ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        curriculum_data = math_service._get_curriculum_data(request)
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 40, 'total': 100, 'status': 'ë¬¸ì œ ìœ í˜• ë¶„ì„ ì¤‘...'}
        )
        
        # ë¬¸ì œ ìœ í˜• ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        problem_types = math_service._get_problem_types(request.chapter.chapter_name)
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 60, 'total': 100, 'status': 'AIë¡œ ë¬¸ì œ ìƒì„± ì¤‘...'}
        )
        
        # AI ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ë¬¸ì œ ìƒì„±
        generated_problems = math_service._generate_problems_with_ai(
            curriculum_data=curriculum_data,
            problem_types=problem_types,
            request=request
        )
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 80, 'total': 100, 'status': 'ë¬¸ì œ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...'}
        )
        
        # ìƒì„± ì„¸ì…˜ ì €ì¥
        generation_session = MathProblemGeneration(
            generation_id=generation_id,
            school_level=request.school_level.value,
            grade=request.grade,
            semester=request.semester.value,
            unit_number=request.unit_number,
            unit_name=request.chapter.unit_name,
            chapter_number=request.chapter.chapter_number,
            chapter_name=request.chapter.chapter_name,
            problem_count=request.problem_count.value_int,
            difficulty_ratio=request.difficulty_ratio.model_dump(),
            problem_type_ratio=request.problem_type_ratio.model_dump(),
            user_text=request.user_text,
            actual_difficulty_distribution=math_service._calculate_difficulty_distribution(generated_problems),
            actual_type_distribution=math_service._calculate_type_distribution(generated_problems),
            total_generated=len(generated_problems),
            created_by=user_id
        )
        
        db.add(generation_session)
        db.flush()
        
        # ìƒì„±ëœ ë¬¸ì œë“¤ì„ ì›Œí¬ì‹œíŠ¸ì— ì—°ê²°í•˜ì—¬ ì €ì¥
        problem_responses = []
        for i, problem_data in enumerate(generated_problems):
            problem = Problem(
                worksheet_id=worksheet.id,
                sequence_order=i + 1,
                problem_type=problem_data.get("problem_type", "multiple_choice"),
                difficulty=problem_data.get("difficulty", "B"),
                question=problem_data.get("question", ""),
                choices=json.dumps(problem_data.get("choices")) if problem_data.get("choices") else None,
                correct_answer=problem_data.get("correct_answer", ""),
                explanation=problem_data.get("explanation", ""),
                latex_content=problem_data.get("latex_content"),
                has_diagram=str(problem_data.get("has_diagram", False)).lower(),
                diagram_type=problem_data.get("diagram_type"),
                diagram_elements=json.dumps(problem_data.get("diagram_elements")) if problem_data.get("diagram_elements") else None
            )
            
            db.add(problem)
            db.flush()
            
            # GeneratedProblemSet ì œê±°ë¨ - Problem í…Œì´ë¸”ì˜ sequence_orderë¡œ ëŒ€ì²´
            
            # ì‘ë‹µìš© ë°ì´í„° ìƒì„±
            problem_responses.append({
                "id": problem.id,
                "sequence_order": i + 1,
                "problem_type": problem.problem_type,
                "difficulty": problem.difficulty,
                "question": problem.question,
                "choices": json.loads(problem.choices) if problem.choices else None,
                "correct_answer": problem.correct_answer,
                "explanation": problem.explanation,
                "latex_content": problem.latex_content,
                "has_diagram": problem.has_diagram == "true",
                "diagram_type": problem.diagram_type,
                "diagram_elements": json.loads(problem.diagram_elements) if problem.diagram_elements else None
            })
        
        # ì›Œí¬ì‹œíŠ¸ ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        worksheet.actual_difficulty_distribution = math_service._calculate_difficulty_distribution(generated_problems)
        worksheet.actual_type_distribution = math_service._calculate_type_distribution(generated_problems)
        worksheet.status = WorksheetStatus.COMPLETED
        worksheet.completed_at = datetime.now()
        
        db.commit()
        
        # ì„±ê³µ ê²°ê³¼ ë°˜í™˜
        result = {
            "generation_id": generation_id,
            "worksheet_id": worksheet.id,
            "school_level": request.school_level.value,
            "grade": request.grade,
            "semester": request.semester.value,
            "unit_name": request.chapter.unit_name,
            "chapter_name": request.chapter.chapter_name,
            "problem_count": request.problem_count.value_int,
            "difficulty_ratio": request.difficulty_ratio.model_dump(),
            "problem_type_ratio": request.problem_type_ratio.model_dump(),
            "user_prompt": request.user_text,
            "actual_difficulty_distribution": math_service._calculate_difficulty_distribution(generated_problems),
            "actual_type_distribution": math_service._calculate_type_distribution(generated_problems),
            "problems": problem_responses,
            "total_generated": len(generated_problems),
            "created_at": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›Œí¬ì‹œíŠ¸ ìƒíƒœë¥¼ FAILEDë¡œ ë³€ê²½
        if 'worksheet' in locals():
            worksheet.status = WorksheetStatus.FAILED
            worksheet.error_message = str(e)
            db.commit()
        
        # íƒœìŠ¤í¬ ì‹¤íŒ¨ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        self.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ë¬¸ì œ ìƒì„± ì‹¤íŒ¨'}
        )
        raise
        
    finally:
        db.close()


@celery_app.task(bind=True, name="app.tasks.grade_problems_mixed_task")
def grade_problems_mixed_task(self, worksheet_id: int, multiple_choice_answers: dict, canvas_answers: dict, user_id: int, handwritten_image_data: dict = None):
    """í˜¼í•©í˜• ì±„ì  íƒœìŠ¤í¬ - ê°ê´€ì‹: ì²´í¬ë°•ìŠ¤, ì„œìˆ í˜•/ë‹¨ë‹µí˜•: OCR"""
    
    task_id = self.request.id
    db = SessionLocal()
    
    try:
        from .services.ai_service import AIService
        ai_service = AIService()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 0, 'total': 100, 'status': 'ì±„ì  ì¤€ë¹„ ì¤‘...'}
        )
        
        # ì›Œí¬ì‹œíŠ¸ì™€ ë¬¸ì œë“¤ ì¡°íšŒ
        worksheet = db.query(Worksheet).filter(Worksheet.id == worksheet_id).first()
        if not worksheet:
            raise ValueError("ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        problems = db.query(Problem).filter(Problem.worksheet_id == worksheet_id).all()
        total_count = len(problems)
        
        # ë¬¸ì œìˆ˜ì— ë”°ë¥¸ ë°°ì  ê³„ì‚°
        points_per_problem = 10 if total_count == 10 else 5 if total_count == 20 else 100 // total_count
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'OCRë¡œ ì†ê¸€ì”¨ ë‹µì•ˆ ì¶”ì¶œ ì¤‘...'}
        )
        
        # ê° ë¬¸ì œë³„ OCR ê²°ê³¼ ì €ì¥
        ocr_results = {}
        if canvas_answers:
            import base64
            for problem_id, canvas_data in canvas_answers.items():
                if canvas_data and canvas_data.startswith('data:image/png;base64,'):
                    try:
                        # base64 ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        image_data = canvas_data.split(',')[1]
                        handwritten_image_data = base64.b64decode(image_data)
                        
                        # ë¬¸ì œë³„ OCR ì²˜ë¦¬
                        raw_ocr_text = ai_service.ocr_handwriting(handwritten_image_data)
                        normalized_ocr_text = _normalize_fraction_text(raw_ocr_text)
                        ocr_results[problem_id] = normalized_ocr_text
                        print(f"ğŸ” ë””ë²„ê·¸: ë¬¸ì œ {problem_id} OCR ì›ë³¸: {raw_ocr_text[:50]}...")
                        print(f"ğŸ” ë””ë²„ê·¸: ë¬¸ì œ {problem_id} OCR ì •ê·œí™”: {normalized_ocr_text[:50]}...")
                    except Exception as e:
                        print(f"ğŸ” OCR ì˜¤ë¥˜ (ë¬¸ì œ {problem_id}): {str(e)}")
                        ocr_results[problem_id] = ""
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 20, 'total': 100, 'status': 'ë‹µì•ˆ ë¶„ì„ ë° ì±„ì  ì¤‘...'}
        )
        
        # ì±„ì  ê²°ê³¼ ì €ì¥
        grading_results = []
        correct_count = 0
        total_score = 0
        
        for i, problem in enumerate(problems):
            if problem.problem_type == "multiple_choice":
                # ê°ê´€ì‹: ì²´í¬ë°•ìŠ¤ë¡œ ë°›ì€ ë‹µì•ˆ ì‚¬ìš©
                user_answer = multiple_choice_answers.get(str(problem.id), "")
                result = _grade_objective_problem(problem, user_answer, points_per_problem)
                result["input_method"] = "checkbox"
            else:
                # ì„œìˆ í˜•/ë‹¨ë‹µí˜•: í•´ë‹¹ ë¬¸ì œì˜ ê°œë³„ OCR ê²°ê³¼ ì‚¬ìš©
                user_answer = ocr_results.get(str(problem.id), "")
                print(f"ğŸ” ë””ë²„ê·¸: ë¬¸ì œ {problem.id} ë‹µì•ˆ: '{user_answer}'")
                
                if problem.problem_type == "essay":
                    result = _grade_essay_problem(ai_service, problem, user_answer, points_per_problem)
                else:  # short_answer
                    result = _grade_objective_problem(problem, user_answer, points_per_problem)
                result["input_method"] = "handwriting_ocr"
            
            grading_results.append(result)
            
            if result["is_correct"]:
                correct_count += 1
            total_score += result.get("score", 0)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = 20 + (i + 1) / total_count * 70
            self.update_state(
                state='PROGRESS',
                meta={'current': progress, 'total': 100, 'status': f'ì±„ì  ì¤‘... ({i+1}/{total_count})'}
            )
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 95, 'total': 100, 'status': 'ê²°ê³¼ ì €ì¥ ì¤‘...'}
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì±„ì  ê²°ê³¼ ì €ì¥
        from .models.grading_result import GradingSession, ProblemGradingResult
        
        grading_session = GradingSession(
            worksheet_id=worksheet_id,
            celery_task_id=task_id,
            total_problems=total_count,
            correct_count=correct_count,
            total_score=total_score,
            max_possible_score=total_count * points_per_problem,
            points_per_problem=points_per_problem,
            ocr_results=ocr_results,
            multiple_choice_answers=multiple_choice_answers,
            input_method="canvas",
            graded_by=user_id
        )
        
        db.add(grading_session)
        db.flush()
        
        # ë¬¸ì œë³„ ì±„ì  ê²°ê³¼ ì €ì¥
        for result_item in grading_results:
            problem_result = ProblemGradingResult(
                grading_session_id=grading_session.id,
                problem_id=result_item["problem_id"],
                user_answer=result_item.get("user_answer", ""),
                actual_user_answer=result_item.get("actual_user_answer", result_item.get("user_answer", "")),
                correct_answer=result_item["correct_answer"],
                is_correct=result_item["is_correct"],
                score=result_item["score"],
                points_per_problem=result_item["points_per_problem"],
                problem_type=result_item["problem_type"],
                input_method=result_item.get("input_method", "canvas"),
                ai_score=result_item.get("ai_score"),
                ai_feedback=result_item.get("ai_feedback"),
                strengths=result_item.get("strengths"),
                improvements=result_item.get("improvements"),
                keyword_score_ratio=result_item.get("keyword_score_ratio"),
                explanation=result_item.get("explanation", "")
            )
            db.add(problem_result)
        
        db.commit()
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            "grading_session_id": grading_session.id,
            "worksheet_id": worksheet_id,
            "total_problems": total_count,
            "correct_count": correct_count,
            "total_score": total_score,
            "points_per_problem": points_per_problem,
            "max_possible_score": total_count * points_per_problem,
            "ocr_results": ocr_results,
            "multiple_choice_answers": multiple_choice_answers,
            "grading_results": grading_results,
            "graded_at": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        self.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ì±„ì  ì‹¤íŒ¨'}
        )
        raise
        
    finally:
        db.close()


@celery_app.task(bind=True, name="app.tasks.grade_problems_task")
def grade_problems_task(self, worksheet_id: int, image_data: bytes, user_id: int):
    """ë¹„ë™ê¸° ë¬¸ì œ ì±„ì  íƒœìŠ¤í¬ - OCR ê¸°ë°˜ ì±„ì """
    
    task_id = self.request.id
    db = SessionLocal()
    
    try:
        from .services.ai_service import AIService
        ai_service = AIService()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 0, 'total': 100, 'status': 'ì±„ì  ì¤€ë¹„ ì¤‘...'}
        )
        
        # ì›Œí¬ì‹œíŠ¸ì™€ ë¬¸ì œë“¤ ì¡°íšŒ
        worksheet = db.query(Worksheet).filter(Worksheet.id == worksheet_id).first()
        if not worksheet:
            raise ValueError("ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        problems = db.query(Problem).filter(Problem.worksheet_id == worksheet_id).all()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'OCRë¡œ ë‹µì•ˆ ì¶”ì¶œ ì¤‘...'}
        )
        
        # OCRë¡œ í•™ìƒ ë‹µì•ˆ ì¶”ì¶œ
        raw_ocr_text = ai_service.ocr_handwriting(image_data)
        if not raw_ocr_text:
            raise ValueError("ë‹µì•ˆì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # OCR í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë¶„ìˆ˜ ì •ê·œí™”)
        ocr_text = _normalize_fraction_text(raw_ocr_text)
        print(f"ğŸ” OCR ì „ì²˜ë¦¬: '{raw_ocr_text}' â†’ '{ocr_text}'")
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 20, 'total': 100, 'status': 'ë‹µì•ˆ ë¶„ì„ ì¤‘...'}
        )
        
        # ì±„ì  ê²°ê³¼ ì €ì¥
        grading_results = []
        correct_count = 0
        total_score = 0
        total_count = len(problems)
        
        # ë¬¸ì œìˆ˜ì— ë”°ë¥¸ ë°°ì  ê³„ì‚°
        points_per_problem = 10 if total_count == 10 else 5 if total_count == 20 else 100 // total_count
        
        for i, problem in enumerate(problems):
            # OCR í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ë¬¸ì œì˜ ë‹µì•ˆ ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬í˜„)
            # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë‹µì•ˆ ë§¤ì¹­ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
            user_answer = _extract_answer_from_ocr(ocr_text, problem.id, i + 1)
            
            # ë¬¸ì œ ìœ í˜•ë³„ ì±„ì  ì²˜ë¦¬
            if problem.problem_type == "essay":
                # ì„œìˆ í˜•: 1ì°¨ í‚¤ì›Œë“œ ê²€ì‚¬ â†’ 2ì°¨ AI ì±„ì 
                result = _grade_essay_problem(ai_service, problem, user_answer, points_per_problem)
            else:
                # ê°ê´€ì‹/ë‹¨ë‹µí˜•: ì§ì ‘ ë¹„êµ
                result = _grade_objective_problem(problem, user_answer, points_per_problem)
            
            grading_results.append(result)
            
            if result["is_correct"]:
                correct_count += 1
            total_score += result.get("score", 0)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = 20 + (i + 1) / total_count * 70
            self.update_state(
                state='PROGRESS',
                meta={'current': progress, 'total': 100, 'status': f'ì±„ì  ì¤‘... ({i+1}/{total_count})'}
            )
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚° (ì´ì  ê¸°ì¤€)
        final_total_score = total_score
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 95, 'total': 100, 'status': 'ê²°ê³¼ ì €ì¥ ì¤‘...'}
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì±„ì  ê²°ê³¼ ì €ì¥
        from .models.grading_result import GradingSession, ProblemGradingResult
        
        grading_session = GradingSession(
            worksheet_id=worksheet_id,
            celery_task_id=task_id,
            total_problems=total_count,
            correct_count=correct_count,
            total_score=final_total_score,
            max_possible_score=total_count * points_per_problem,
            points_per_problem=points_per_problem,
            ocr_text=ocr_text,
            input_method="image_upload",
            graded_by=user_id
        )
        
        db.add(grading_session)
        db.flush()
        
        # ë¬¸ì œë³„ ì±„ì  ê²°ê³¼ ì €ì¥
        for result_item in grading_results:
            problem_result = ProblemGradingResult(
                grading_session_id=grading_session.id,
                problem_id=result_item["problem_id"],
                user_answer=result_item.get("user_answer", ""),
                actual_user_answer=result_item.get("actual_user_answer", result_item.get("user_answer", "")),
                correct_answer=result_item["correct_answer"],
                is_correct=result_item["is_correct"],
                score=result_item["score"],
                points_per_problem=result_item["points_per_problem"],
                problem_type=result_item["problem_type"],
                input_method="handwriting_ocr",
                ai_score=result_item.get("ai_score"),
                ai_feedback=result_item.get("ai_feedback"),
                strengths=result_item.get("strengths"),
                improvements=result_item.get("improvements"),
                keyword_score_ratio=result_item.get("keyword_score_ratio"),
                explanation=result_item.get("explanation", "")
            )
            db.add(problem_result)
        
        db.commit()
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            "grading_session_id": grading_session.id,
            "worksheet_id": worksheet_id,
            "total_problems": total_count,
            "correct_count": correct_count,
            "total_score": final_total_score,
            "points_per_problem": points_per_problem,
            "max_possible_score": total_count * points_per_problem,
            "ocr_text": ocr_text,
            "grading_results": grading_results,
            "graded_at": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        self.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ì±„ì  ì‹¤íŒ¨'}
        )
        raise
        
    finally:
        db.close()


def _normalize_fraction_text(text: str) -> str:
    """OCR í…ìŠ¤íŠ¸ ì •ê·œí™” - ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ ì‚¬ìš©"""
    from .services.grading_service import GradingService
    grading_service = GradingService()
    return grading_service.normalize_fraction_text(text)

def _normalize_answer_for_comparison(answer: str) -> str:
    """ë‹µì•ˆ ì •ê·œí™” - ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ ì‚¬ìš©"""
    from .services.grading_service import GradingService
    grading_service = GradingService()
    return grading_service.normalize_answer_for_comparison(answer)

def _extract_answer_from_ocr(ocr_text: str, problem_id: int, problem_number: int) -> str:
    """OCR ë‹µì•ˆ ì¶”ì¶œ - ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ ì‚¬ìš©"""
    from .services.ocr_service import OCRService
    ocr_service = OCRService()
    return ocr_service.extract_answer_from_text(ocr_text, problem_id, problem_number)


def _grade_essay_problem(ai_service, problem: Problem, user_answer: str, points_per_problem: int) -> dict:
    """ì„œìˆ í˜• ë¬¸ì œ ì±„ì  - ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ ì‚¬ìš©"""
    from .services.async_task_service import AsyncTaskService
    
    task_service = AsyncTaskService()
    
    # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
    keyword_result = task_service._calculate_keyword_score(problem.correct_answer, user_answer)
    
    # AI ì±„ì 
    ai_result = ai_service.grade_math_answer(
        question=problem.question,
        correct_answer=problem.correct_answer,
        student_answer=user_answer,
        explanation=problem.explanation,
        problem_type="essay"
    )
    
    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
    ai_score_ratio = ai_result.get("score", 0) / 100
    final_score = points_per_problem * ai_score_ratio
    
    return {
        "problem_id": problem.id,
        "problem_type": "essay",
        "user_answer": user_answer,
        "correct_answer": problem.correct_answer,
        "is_correct": final_score >= (points_per_problem * 0.6),
        "score": final_score,
        "points_per_problem": points_per_problem,
        "keyword_score_ratio": keyword_result["ratio"],
        "ai_score": ai_result.get("score", 0),
        "ai_feedback": ai_result.get("feedback", ""),
        "strengths": ai_result.get("strengths", ""),
        "improvements": ai_result.get("improvements", ""),
        "explanation": problem.explanation
    }


def _grade_objective_problem(problem: Problem, user_answer: str, points_per_problem: int) -> dict:
    """ê°ê´€ì‹/ë‹¨ë‹µí˜• ë¬¸ì œ ì±„ì  - ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ ì‚¬ìš©"""
    from .services.async_task_service import AsyncTaskService
    
    task_service = AsyncTaskService()
    return task_service._grade_objective_sync(problem, user_answer, points_per_problem)


@celery_app.task(bind=True, name="app.tasks.get_task_status")
def get_task_status(self, task_id: str):
    """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
    from celery.result import AsyncResult
    
    result = AsyncResult(task_id, app=celery_app)
    
    return {
        "task_id": task_id,
        "status": result.status,
        "result": result.result if result.successful() else None,
        "info": result.info
    }